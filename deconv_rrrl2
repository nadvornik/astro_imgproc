#!/usr/bin/env python3

# Copyright (C) 2017 Vladimir Nadvornik
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.


import tifffile
import numpy as np
import cv2
import sys
import os
import argparse
import pfor
from cv2t import cv2t
import gc
import pickle

from astro_utils import noise_level, poly_bg, poly_res, poly_array,  extrapolate_transp
from centroid import centroid, sym_center

from scipy.optimize import curve_fit

def crop_param(s):
	try:
		if s is None:
			return None
		x1,x2,y1,y2 = s.split(',')
		return (slice(int(y1),int(y2)), slice(int(x1),int(x2)))
	except:
    		raise argparse.ArgumentTypeError("Filter param must be r,s")


parser = argparse.ArgumentParser()
parser.add_argument("outfile",
                    help="output tiff file")
parser.add_argument("infile", nargs='+',
                    help="input tiff file")

parser.add_argument("--psffile",
                    help="psf tiff file if different from infile")

parser.add_argument("--iter", type=int, default=10,
                    help="number of iteration")
parser.add_argument("--diameter", type=int, default=15,
                    help="psf diameter")
parser.add_argument("--tiles", type=int, default=4,
                    help="number of tiles NxN")
parser.add_argument('--var-psf', action='store_true',
                    help="variable psf")

parser.add_argument("--psf-filter-sigma-res", type=float, default=1.2,
                    help="psf filter")
parser.add_argument("--psf-filter-sigma", type=float, default=0.5,
                    help="psf filter final sigma")
parser.add_argument("--psf-filter-moffat-scale", type=float, default=1,
                    help="psf filter moffat scale")

parser.add_argument("--update-iter", type=int, default=0,
                    help="start updating at iteration i")
parser.add_argument("--update-accel", type=float, default=20,
                    help="update accel")

parser.add_argument("--blur-iter", type=int, default=0,
                    help="start updating at iteration i")
parser.add_argument("--blur-sigma", type=float, default=2,
                    help="update accel")

parser.add_argument("--reg2", type=float, default=[0.1], nargs = '+',
                    help="regularization2")
parser.add_argument("--reg-lambda2", type=float, default=[2.0], nargs = '+',
                    help="lambda2")
parser.add_argument("--reg4", type=float, default=[0.1], nargs = '+',
                    help="regularization4")
parser.add_argument("--reg-lambda4", type=float, default=[2.0], nargs = '+',
                    help="lambda4")
parser.add_argument("--lambda-eval-iter", type=int, default=1000,
                    help="stop updating lambda at iteration i")
parser.add_argument("--reg-plus", type=float, default=1,
                    help="reg plus")



parser.add_argument("--erode", type=float, default=0,
                    help="erode accel")
parser.add_argument("--erode-iter", type=int, default=0,
                    help="stop erode at iteration i")

parser.add_argument("--top-thres", type=float, default=0.5,
                    help="top-thres")

parser.add_argument("--robustness", type=float, default=1000,
                    help="robustness")


parser.add_argument("--gaussian", type=float, default=0.0,
                    help="blind with gaussian")

parser.add_argument("--gradient-radius", type=int, default=300,
                    help="gradient radius")

parser.add_argument("--crop", type=crop_param, default=None,
                    help="crop x1,x2,y1,y2")

parser.add_argument("--scale", type=float, default=1,
                    help="output scale")

parser.add_argument("--zero", type=float, default=1024,
                    help="zero level")

parser.add_argument("--show-gamma", type=float, default=0.1,
                    help="display gamma")

parser.add_argument("--overexp", type=float, default=0.8,
                    help="overexp level")

parser.add_argument("--tile-overlap", type=float, default=0.25,
                    help="tile overlap")

parser.add_argument("--weight-dilate", type=int, default=2,
                    help="weight dilate")

parser.add_argument("--save-psf",
                    help="save psf")
parser.add_argument("--load-psf",
                    help="load psf")


args = parser.parse_args()

while len(args.reg2) < len(args.reg_lambda2):
	args.reg2.append(args.reg2[-1])
while len(args.reg_lambda2) < len(args.reg2):
	args.reg_lambda2.append(args.reg_lambda2[-1])
while len(args.reg4) < len(args.reg_lambda4):
	args.reg4.append(args.reg4[-1])
while len(args.reg_lambda4) < len(args.reg4):
	args.reg_lambda4.append(args.reg_lambda4[-1])


def normalize(img):
        dst = np.empty_like(img)
        return cv2.normalize(img, dst, alpha = 0, beta = 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)


hfr_size = args.diameter
hfr_mat_mask = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (hfr_size * 2 + 1, hfr_size * 2 + 1))
hfr_mat = cv2.multiply(np.array([[(x**2 + y**2)**0.5 for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)

def hfr(a):
	s = cv2.sumElems(cv2.multiply(a,  hfr_mat_mask, dtype=cv2.CV_32FC1))[0]
	if s == 0.0:
		return hfr_size
	r = cv2.sumElems(cv2.multiply(a,  hfr_mat, dtype=cv2.CV_32FC1))[0] / s
	return r

def poly_array2(X, Y):
	res = np.empty([X.shape[0], 4])
	res[:, 0] = 1
	res[:, 1] = X ** 2
	res[:, 2] = Y ** 2
	res[:, 3] = Y * X

	return res

def fit_psf(psf):
	xy = np.array([ [float(x - args.diameter) / args.diameter, float(y - args.diameter) / args.diameter] for y in range(0, args.diameter * 2 + 1) for x in range(0, args.diameter * 2 + 1) ], dtype=np.float)
	A0 = poly_array2(xy[:, 0], xy[:, 1])

	psf = cv2.normalize(psf, psf, alpha = 0, beta = 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32FC1)
	#cv2t.imshow("psf1", normalize(psf))
		
	bpsf = cv2.GaussianBlur(psf,(5, 5),0)
	avg = np.mean(bpsf)
	#cv2t.imshow("bpsf", normalize(bpsf))
		
		
	
	init_keep = np.array([ [(x - args.diameter) ** 2 +  (y - args.diameter) ** 2 < 10 ** 2] for y in range(0, args.diameter * 2 + 1) for x in range(0, args.diameter * 2 + 1) ], dtype=np.int8).flatten()
	keep = np.where(init_keep > 0)
	A = A0[keep]
	bpsf_f = bpsf.flatten()[keep]
			
	for i in range(0, 10):
		#print "lst", A, bpsf_f, keep
		c = np.linalg.lstsq(A, bpsf_f)[0]
		res = np.dot(A0, c)
		keep = np.where(res > avg)
		if keep[0].shape[0] == 0:
			break
		A = A0[keep]
		bpsf_f = bpsf.flatten()[keep]
			
		
	#print c
	psffit = np.dot(A0, c).reshape((args.diameter * 2 + 1,args.diameter * 2 + 1))
		
	skip = np.where(psffit < avg)
	if len(skip[0] > 0):
		avg = np.mean(bpsf[skip])
		skip = np.where(psffit < avg)
		
	psffit[skip] = 0
	#cv2t.imshow("psffit", normalize(psffit))
		
	psf -= avg
	psf[skip] = 0
	psf[np.where(psf < 0)] = 0
		
	#cv2t.imshow("psf2", normalize(psf))

	mask = np.ones((args.diameter * 2 + 1,args.diameter * 2 + 1), dtype = np.uint8)
	mask[skip] = 0
	
	kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
	mask = cv2.dilate(mask, kernel)


        # c^2 < 4ab

	if c[3]**2 > 4 * c[1] * c[2]  or c[0] < 0 or len(keep) == 0:
		area = (args.diameter * 2 + 1) ** 2
	else:
		area = (args.diameter * 2 + 1) ** 2 - len(skip[0])
	
	
	#print "area", area
	#cv2t.waitKey(0)
	return psf, area, mask


def find_ptlist(img):
	kernel = np.ones((args.diameter,args.diameter),np.uint8)
	img = np.array(img, dtype=np.float32, copy=True)
	img = cv2.medianBlur(img, 3)
	bg = cv2.GaussianBlur(img,(15, 15),0)
	img_sub = cv2.subtract(img, bg)
	bl = cv2.GaussianBlur(img_sub,(9, 9),0)
	dil = cv2.dilate(bl, kernel)

	cmpmax = cv2.compare(bl, dil, cv2.CMP_GE)
	
	

	#er = cv2.erode(bl, kernel)
	#bg = cv2.GaussianBlur(er,(19, 19),0)
	#img -= bg
	#img[np.where(img < 0)] = 0

	sigma = noise_level(img)
	cmpmax[np.where(img_sub <= sigma * 10)] = 0
	
	cv2t.imshow("cmpmax", normalize(cmpmax))

	ptlist = []
	for (y0, x0) in zip(*cmpmax.nonzero()):
		if x0 < args.diameter or y0 < args.diameter or x0 > w - args.diameter - 1 or y0 > h - args.diameter - 1:
			continue
		
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x0, y0))
		psf, area, mask = fit_psf(psf)
		(x, y) = sym_center(psf)
		print("pt", x0, y0, x, y)
		x += x0
		y += y0
		
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		psf, area, mask = fit_psf(psf)
		
		print("area", area)
		if area > args.diameter ** 2 * 1.5:
			continue
		
		if area < 20:
			continue
		
			
		hf = hfr(psf)
		print("area", area, hf)
		

		ptlist.append([y, x, float(img[y0, x0]), hf, mask, 0 ])


	return ptlist

def filter_ptlist(img, i_ptlist):
	minv = 512 / 65535.0

	maxval = np.max(img)

	(h,w) = img.shape
	
	ptlist = []
	hfrlist = []

	for (y, x, v, h, mask, low) in i_ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		
		bl = cv2.GaussianBlur(cv2.medianBlur(psf, 5), (7, 7), 0)
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl)
		
		if maxVal - minVal < minv:
			continue
		
		if maxVal > maxval * 0.9:
			continue
		
		psf -= minVal
		psf = np.abs(psf)
		psf[np.where(mask == 0)] = 0
		
		
		hf = hfr(psf)
		hfrlist.append([y, x, hf, maxVal - minVal])
		ptlist.append([y, x, maxVal, hf, mask, minVal])

	hfrlist = np.array(hfrlist)
	Y = hfrlist[:,0]
	X = hfrlist[:,1]
	ahfr0 = hfrlist[:,2]
	A0 = poly_array(X, Y, 3)
	
	W = np.sqrt(hfrlist[:,3])
	A0 *= W[:,np.newaxis]
	ahfr0 *= W
	
	ahfr = ahfr0
	A = A0
	
	for i in range(0, 10):
	
		coef = np.linalg.lstsq(A, ahfr)[0]
		gmedhfr = np.dot(A, coef)
		
		gsigma2 = np.mean((ahfr - gmedhfr)**2)
		#gs_coef = np.linalg.lstsq(A, gsigma2)[0]
		#gsigma2 = np.dot(A, gs_coef)
		gmedhfr0 = np.dot(A0, coef)
		gkeep = np.where((ahfr0 - gmedhfr0)**2 <= gsigma2 * 6)
		
		A = A0[gkeep]
		ahfr = ahfr0[gkeep]
		print("gsigma2", gsigma2, 'len', len(ahfr))
	
	print(gkeep)
	ptlist = [ptlist[i] for i in gkeep[0]]
	
	return ptlist
	
def set_psf_level(img, ptlist):
	minv = 256 / 65535.0
	img = np.array(img, dtype=np.float32)
	res = []
	for p in ptlist:
		(y, x, v, hfr, mask, low) = p
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		low = np.median(psf[np.where(mask > 0)])
		
		
		#low = poly_bg(psf, order = 1, scale = 1, it = 10)[:, :, 0]
		
		psf -= low
		psf[np.where(psf < 0)] = 0
		psf[np.where(mask == 0)] = 0
		v = np.max(psf)
		if v > minv:
			res.append((y, x, v, hfr, mask, low))
	return res



def get_psf_list(img, ptlist):
	img = np.array(img, dtype=np.float32)
	
	psflist = []
	for (y, x, v, hfr, mask, low) in ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))

		
#		psf_scale = psf - low
#		psf_scale[np.where(psf < 0)] = 0
		
#		psf -= low
#		psf /= psf_scale.sum()
		
		psflist.append(psf)
	return psflist


def rl_simple(src, psf, it):
	src = np.array(src, dtype=np.float64)
	res = np.ones_like(src)
	for i in range(0, it):
		b_res = psf.apply(res)
		cor = cv2.divide(src, b_res)
		cor[np.where(cor < 0.00001)] = 0.00001
		cor = psf.apply(cor, flip = True)
		res *= cor
	return res


def rrrl_simple(src, psf, it):
	psf_zero = 0.001
	scales = np.ones((len(src),), dtype=np.float64)
	weights = np.ones((len(src),), dtype=np.float64)
	for i in range(len(src)):
		bl = cv2.GaussianBlur(cv2.medianBlur(src[i], 5), (7, 7), 0)
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl)
		
		src[i] -= minVal - psf_zero
		scales[i] = 1 / (maxVal + 0.00000000001 - minVal) 
		weights[i] = (maxVal - minVal) ** 0.5
		
		
	src = np.atleast_3d(src)
	src[np.where(src < 0)] = 0
	
	res = np.mean(src, axis = 0)
	res = cv2.GaussianBlur(res, (5,5), 0)
	
	
	for i in range(0, it):
		kappa = (it - i) / it * 10 + 2
		b_res = psf.apply(res)
		b_res[np.where(b_res < 0.0000001)] = 0.0000001
		
		sum_w = np.zeros_like(res)
		sum_corw = np.zeros_like(res)
		
		scaled_src = src * scales[:, None, None] + psf_zero * (1.0 - scales[:, None, None])
		
		cor = scaled_src / b_res[None, :, :]
		cor[np.where(cor < 0.00001)] = 0.00001
		
		dat = b_res[None, :, :] - scaled_src * (1.0 - np.log(cor))
		dat = dat * dat
		
		var = np.mean(dat, axis = 0)
		clip = np.where(dat > (var * kappa**2)[None, :, :])
		
		
		dat = (dat + 1.0 / 1000.0**4) ** -0.25 * weights[:, None, None]
		
		dat[clip] = 0.0
		
		for c in range(0, len(src)):
			cor_mean = np.average(cor[c], weights = dat[c] + 0.0000001)
			scales[c] /= cor_mean

			corw = psf.apply(cv2.multiply(dat[c], cor[c]), flip = True)
			w =  psf.apply(dat[c], flip = True)

			corw[np.where(corw < 0.0)] = 0.0
			w[np.where(w < 0.0)] = 0.0

			sum_w += w
			sum_corw += corw
		
		cor = cv2.divide(sum_corw, sum_w)
		res *= cor
	#print(scales)
	res -= psf_zero
	res[np.where(res < 0)] = 0
	return res, dat
		



class PsfGauss:
	def __init__(self, size, sigma):
		self.size = size
		self.sigma = sigma
	
	def apply(self, img, flip = False):
		return cv2.GaussianBlur(img, (self.size, self.size), self.sigma)

class PsfMoffat:
	def __init__(self, size, alpha = 1, beta=4.765, ring=10, ring_s = 1, psf = None, residual = None):
		self.size = size
		self.mx = (size - 1) / 2.0
		self.my = (size - 1) / 2.0
		
		if psf is not None:
			self.fit(psf, residual)
		else:
			self.set(alpha, beta, ring, ring_s)

	def fit(self, psf, residual = None):
		r2 = np.array([[ (x - self.mx) ** 2 + (y - self.my) ** 2 for x in range(0, self.size)] for y in range(0, self.size)])
	
		def moffat2d(yx, alpha, beta, mag, shift):
			y, x = yx
			#print(alpha, beta, mag, shift)
			moffat = (1 + (r2 / (alpha * alpha))) ** -beta
			if residual is not None:
				moffat = cv2.filter2D(residual, -1, moffat)
			#cv2t.imshow("iter", normalize(moffat ** 0.4))
			ret = shift + mag * moffat[x, y]
			#print(ret)
			return ret

		cv2t.imshow("src", normalize(psf ** 0.4))
		if residual is not None:
			cv2t.imshow("residual", normalize(residual ** 0.4))

		x0 = np.arange(self.size)
		y0 = np.arange(self.size)
		y, x = np.meshgrid(y0, x0)
		yx = (y.ravel(), x.ravel())
		z = psf.ravel() * 1000.0

		shift = np.amin(z)
		mag = np.amax(z) - shift
		
		try:
			popt, pcov = curve_fit(moffat2d, yx, z, p0 = [1, 5, mag, shift], bounds = ([0.01, 1, 0, 0], [4.0, 10, np.inf, np.inf]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point')
			print ("fit1a", popt)
			sigma = z - moffat2d(yx, *popt)
			ss = np.median(sigma ** 2) ** 0.5 * 0.2
			sigma[np.where(sigma < ss)] = ss
			popt, pcov = curve_fit(moffat2d, yx, z, p0 = popt, bounds = ([0.01, 1, 0, 0], [4.0, 10, np.inf, np.inf]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point', sigma = sigma)
			print ("fit1b", popt)
			sigma = z - moffat2d(yx, *popt)
			cv2t.imshow("dif1", normalize(np.reshape(sigma, psf.shape)))

		except  Exception as e:
			print(e)
			popt = [1.0, 4.765, mag, shift]
		self.set(popt[0], popt[1])

	def fit2(self, psf, residual = None):
		r2 = np.array([[ (x - self.mx) ** 2 + (y - self.my) ** 2 for x in range(0, self.size)] for y in range(0, self.size)])
	
		def moffat2d(xy, alpha, ring, ring_s, mag, shift):
			beta = self.beta
			y, x = yx
			#print(alpha, beta, mag, shift)
			moffat = (1 + (r2 / (alpha * alpha))) ** -beta * (1.0 - 1.0 / (1 + (r2 ** 0.5 * ring_s - ring)**4))
			if residual is not None:
				moffat = cv2.filter2D(residual, -1, moffat)
			#cv2t.imshow("iter", normalize(moffat ** 0.4))
			ret = shift + mag * moffat[x, y]
			#print(ret)
			return ret

		cv2t.imshow("src", normalize(psf ** 0.4))
		if residual is not None:
			cv2t.imshow("residual", normalize(residual ** 0.4))

		x0 = np.arange(self.size)
		y0 = np.arange(self.size)
		y, x = np.meshgrid(y0, x0)
		yx = (y.ravel(), x.ravel())
		z = psf.ravel() * 1000.0

		shift = np.amin(z)
		mag = np.amax(z) - shift
		
		try:
			popt, pcov = curve_fit(moffat2d, yx, z, p0 = [1, 2, 1, mag, shift], bounds = ([0.01, 2, 1, 0, 0], [4.0, np.inf, np.inf, np.inf, np.inf]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point')
			print ("fit2a", popt)
			sigma = z - moffat2d(yx, *popt)
			ss = np.median(sigma ** 2) ** 0.5 * 0.2
			sigma[np.where(sigma < ss)] = ss
			popt, pcov = curve_fit(moffat2d, yx, z, p0 = popt, bounds = ([0.01, 2, 1, 0, 0], [4.0, np.inf, np.inf, np.inf, np.inf]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point', sigma = sigma)
			print ("fit2b", popt)
			sigma = z - moffat2d(yx, *popt)
			cv2t.imshow("dif2", normalize(np.reshape(sigma, psf.shape)))
		except  Exception as e: 
			print(e)
			popt = [1.0, 0, 0, mag, shift]
		self.set(popt[0], self.beta, popt[1], popt[2])



	def set(self, alpha, beta, ring = 0, ring_s = 0):
		self.alpha = alpha
		self.beta = beta
		self.ring = ring
		self.ring_s = ring_s
		
		r2 = np.array([[((x - self.mx) **2 + (y - self.my)**2) for x in range(self.size) ] for y in range(self.size) ], dtype=np.float)
		
		self.psf = (1 + r2 / (alpha **2 )) ** -beta
		if ring_s > 0:
			self.psf *= (1.0 - 1.0 / (1 + (r2 ** 0.5 * ring_s - ring)**4))

		cv2t.imshow("moffat", normalize(self.psf ** 0.4))
	
		self.psf /= self.psf.sum()
		
	def interpolate(self, s):
		if s < 0.01:
			s = 0.01
		return PsfMoffat(self.size, self.alpha * s ** 0.5, self.beta / s ** 0.5, self.ring, self.ring_s)
	
	def apply(self, img, flip = False):
		return cv2.filter2D(img, -1, self.psf)

def moffat_mean(moffat_list):
	beta = [p.beta for p in moffat_list]
	print("beta", beta)
	beta = np.median(beta)
	print("med", beta)
	for p in moffat_list:
		p.set(p.alpha, beta, p.ring, p.ring_s)


class Psf:
	def set(self, psf):
		psf = np.array(psf)
		psf[np.where(psf < 0)] = 0
		psf /= psf.sum()
		self.psf = psf
		self.psf_flip = self.psf[::-1, ::-1]
		self.updated = False
		self.center = (0.0, 0.0)
		

	def extract(self, img, ptlist, psf_filter_sigma):
		psflist = get_psf_list(img, ptlist)
		self.from_psflist(psflist, psf_filter_sigma)

	def from_psflist(self, psflist, psf_filter_sigma):
		if len(psflist) == 0:
			return self.gaussian(None, 1.0)
		#psf = rrrl_simple(psflist, PsfMoffat(args.diameter * 2 + 1, 3, 2), 30)
		psf, weights = rrrl_simple(psflist, PsfGauss(args.diameter * 2 + 1, psf_filter_sigma), 50)
		
#		psfgrad = (cv2.Sobel(psf, -1, 1,0,ksize=3)**2 + cv2.Sobel(psf, -1, 0,1,ksize=3)**2) ** 0.5
		#psfgrad2 = (cv2.Sobel(psfgrad, -1, 1,0,ksize=3)**2 + cv2.Sobel(psfgrad, -1, 0,1,ksize=3)**2) ** 0.5
		#cv2t.imshow("psfgrad2" , normalize(psfgrad2))
		
#		med_grad = float(np.mean(psfgrad))
		#print(med_grad)
		
		
		
#		psfgrad[np.where(psfgrad < med_grad * 3)] = 0
#		cv2t.imshow("psfgrad" , normalize(psfgrad))
		
#		floodmask = np.zeros((psf.shape[0] + 2, psf.shape[1] + 2), dtype=np.uint8)
#		cv2.floodFill(psfgrad, floodmask, (0,0), 255, loDiff = 0, upDiff = med_grad * 3, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY)
#		mask = 1 - floodmask[1:-1, 1:-1]
#		cv2t.imshow("psfgradmask", mask * 255)



		


		
		floodmask = np.zeros((psf.shape[0] + 2, psf.shape[1] + 2), dtype=np.uint8)
		bl_psf = cv2.medianBlur(psf, 3)
		bl_psf = cv2.GaussianBlur(bl_psf, (3, 3), 0)
		
		y, x = np.ogrid[-args.diameter:args.diameter + 1, -args.diameter:args.diameter + 1]
		r = np.array((x * x + y * y) ** 0.5 / args.diameter, dtype = np.float32) ** 2
		
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl_psf)
		
		bl_psf_r = bl_psf + r * (maxVal - minVal)
		thr = (maxVal - minVal) / 2.0 + minVal
		
		while True:
			cv2.floodFill(bl_psf_r, floodmask, maxLoc, 2, loDiff = 1000.0, upDiff = 0, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY)
			mask = floodmask[1:-1, 1:-1]
			bl_psf[np.where(mask > 0)] = 0
			minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl_psf)
			if maxVal < thr:
				break
		
		mask[0,:] = 0
		mask[-1,:] = 0
		mask[:, 0] = 0
		mask[:, -1] = 0
		
		cv2t.imshow("psf1" , normalize(psf ** 0.4))
		
#		mask = cv2.erode(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		#border = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))) - mask


		low = np.median(psf)
		psf -= low
		psf[np.where(psf < 0)] = 0
		psf[np.where(mask == 0)] = 0

		thr = np.mean(psf[np.where(mask != 0)]) 
		mask = np.clip(psf, 0, thr) / thr
		cv2t.imshow("mask", mask)
		
		psf *= mask
		
		if psf.sum() == 0:
			psf[args.diameter, args.diameter] += 1
		cv2t.imshow("psf2" , normalize(psf ** 0.4))
			
		self.base_psf = psf
			
		self.target = np.mean(psflist, axis = 0)
		#target = cv2.erode(target, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		self.residual = cv2.GaussianBlur(psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), args.psf_filter_sigma_res)
		#residual = cv2.dilate(residual, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		
		self.moffat = PsfMoffat(args.diameter * 2 + 1, psf = self.target, 
				residual = self.residual)
		psf = self.moffat.apply(psf)
		
		cv2t.imshow("srcfit" , normalize(psf ** 0.4))
		
		self.target = np.average(psflist, axis = 0, weights = weights)
		
		self.set(psf)
		#cv2t.imshow("psf%d" % id(self) , normalize(self.psf ** 0.5))
	
	def fit2(self):
		self.moffat.fit2(self.target, self.residual)
		psf = self.moffat.apply(self.base_psf)
		cv2t.imshow("srcfit2" , normalize(psf ** 0.4))

		self.set(psf)
	
	def interpolate(self, s):
		if self.updated:
			return
		try:
			moffat = self.moffat
			#s = 1.0 - np.clip(s, 0, 1)
			#moffat_i = self.moffat.interpolate(s)
			#psf = moffat.apply(self.base_psf) + self.base_psf - moffat_i.apply(self.base_psf)
			moffat = self.moffat.interpolate(s)
			psf = moffat.apply(self.base_psf)
			self.set(psf)
			cv2t.imshow("moffat", normalize(self.psf ** 0.4))
		except:
			pass
	
	def gaussian(self, img, sigma):
		psf = np.zeros((args.diameter * 2 + 1, args.diameter * 2 + 1), dtype=np.float64)
		psf[args.diameter, args.diameter] = 1
		psf = cv2.GaussianBlur(psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), sigma)
		self.set(psf)

	def update(self, cor_psf, dat, res):
		if not self.updated:
			self.updated = True
			self.psf = cv2.GaussianBlur(self.psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), 0.5)
			
		rs = res.sum()
		if rs == 0:
			return
			
		anchor = (int(res.shape[1] / 2), int(res.shape[0] / 2))
		res = res / rs
		
		cor_psf = cv2.divide(cv2.filter2D(cor_psf * dat, -1, res, anchor = anchor), cv2.filter2D(dat, -1, res, anchor = anchor))
		#cor_psf = cv2.filter2D(cor_psf, -1, res, anchor = anchor)


		cor_psf = np.array(cor_psf, dtype = np.float32)
		cor_psf = cv2.getRectSubPix(cor_psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), (anchor[0] - self.center[0], anchor[1] - self.center[1]))
			
		#cor_psf /= np.mean(cor_psf)
		#print cor_psf
		#print "mean", np.mean(cor_psf)
		cor_psf = np.clip(cor_psf, 0.9, 1.1)
		cor_psf **= args.update_accel
		cor_psf = cv2.GaussianBlur(cor_psf,(3,3), 0)
		cv2t.imshow("cor_psf", normalize(cor_psf))
		if np.all(cor_psf >= 0) and not np.isnan(cor_psf).any():
			self.psf *= cor_psf

		cv2t.imshow("psf", normalize(self.psf ** 0.5))
		
		if self.psf.sum() == 0:
			self.psf[args.diameter, args.diameter] += 1

		self.psf = self.psf / self.psf.sum()
		self.psf_flip = self.psf[::-1, ::-1]

	def apply(self, img, flip = False):
		return cv2.filter2D(img, -1, (self.psf_flip, self.psf)[flip])
	
	def hfr(self):
		
		(x, y) = sym_center(self.psf)
		x += args.diameter
		y += args.diameter
		
		psf = cv2.getRectSubPix(np.float32(self.psf), (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		return hfr(psf)
	
class VarPsf:
	def extract(self, img, ptlist, psf_filter_sigma):

		flatpsflist = []
		psflist = get_psf_list(img, ptlist)
		flatpsflist = np.array(psflist).reshape((len(psflist), -1))
	
		print("flatpsflist", flatpsflist.shape)

	
		cov = np.cov(flatpsflist)
		print("cov", cov)
		w, v = np.linalg.eig(cov)
		print("eig", w)
		print(v)
	
		print("eig shape:", v.shape)
		print("len psflist", len(psflist))
		print("cov shape", cov.shape)
	
		num_comp = min(20, w.shape[0])
	
		psfcomp = []
		self.psfcomplist = []
		for i, ev in enumerate(v):
			psf_s = np.zeros((args.diameter * 2 + 1, args.diameter * 2 + 1), np.float64)
			for j, c in enumerate(ev):
				psf_s += psflist[j] * float(c)
		
			psfcomp.append(psf_s.flatten())
			self.psfcomplist.append(psf_s)
		
			cv2.imwrite("psf%d.tif" % i, normalize(psf_s))
			if (i >= num_comp):
				break
	
		psfcomp = np.array(psfcomp).T
		
		psfcoef = []
		for psf in flatpsflist:
			psfcoef.append(np.linalg.lstsq(psfcomp, psf)[0])
		
		psfcoef = np.array(psfcoef).T
	
		Y = np.array([p[0] for p in ptlist])
		X = np.array([p[1] for p in ptlist])
	
		print("X", X)
		A = poly_array(X / 1000.0, Y / 1000.0, 3)
		print("coef fit")
	
		self.coef_fit = []
		for coefval in psfcoef:
			self.coef_fit.append(np.linalg.lstsq(A, coefval)[0])
	

		print("comp")
		self.comp_scale = []
		for c in self.coef_fit:
			v = poly_res(img.shape, c, 3)
			print(cv2.minMaxLoc(v))
			self.comp_scale.append(v)
		
		self.psfcomplist_flip = [psf[::-1, ::-1] for psf in self.psfcomplist]
		
		self.scale = None
		self.scale = self.apply(np.ones_like(img, dtype = np.float32))
		
		print("scale")
		print(cv2.minMaxLoc(self.scale))

	def apply(self, img, flip = False):
		res = np.zeros_like(img)
		for s, psf in zip(self.comp_scale, (self.psfcomplist_flip, self.psfcomplist)[flip]):
			res += cv2.filter2D(img * s, -1, psf)
		if self.scale is not None:
			res = res / self.scale
		return res


class TilePsf:
	def extract(self, img, ptlist, psf_filter_sigma):
		self.shape = img.shape
		
		stars_tile = len(ptlist) / args.tiles ** 2
		print("stars per tile", stars_tile)
		stars_tile = max(stars_tile, 20)
		h, w = self.shape

		tile_size_h = int((h + args.tiles - 1) / args.tiles)
		tile_size_w = int((w + args.tiles - 1) / args.tiles)
		tile_overlap = int(tile_size_h * args.tile_overlap)
		self.tile_overlap = tile_overlap
		
		self.tiles = []
		for y in range(0, h, tile_size_h):
			for x in range(0, w, tile_size_w):
				ul = (y, x)
				lr = (min(y + tile_size_h, h), min(x + tile_size_w, w))
				
				tile_overlap_e = tile_overlap
				eul_mo = (max(0, y - tile_overlap), max(0, x - tile_overlap))
				elr_mo = (min(y + tile_size_h + tile_overlap, h), min(x + tile_size_w + tile_overlap, w))
				while True:
					eul = (max(0, y - tile_overlap_e), max(0, x - tile_overlap_e))
					elr = (min(y + tile_size_h + tile_overlap_e, h), min(x + tile_size_w + tile_overlap_e, w))
				
					t_ptlist = [ (py - eul[0], px - eul[1], v, hfr, mask, low) for py, px, v, hfr, mask, low in ptlist if py >= eul[0] and px >= eul[1] and py < elr[0] and px < elr[1] ]
					if len(t_ptlist) > stars_tile:
						break
					if eul == (0,0) and elr == (h,w):
						break
					tile_overlap_e *= 2
				if args.var_psf:
					psf = VarPsf()
					psf.extract(img[eul[0] : elr[0], eul[1]: elr[1]], t_ptlist, psf_filter_sigma)
					self.tiles.append((psf, ul, lr, eul, elr))
				else:
					psf = Psf()
					psflist = get_psf_list(img[eul[0] : elr[0], eul[1]: elr[1]], t_ptlist)
					psf.from_psflist(psflist, psf_filter_sigma)
					self.tiles.append((psf, ul, lr, eul_mo, elr_mo))

		moffat_mean([t[0].moffat for t in self.tiles])
		for t in self.tiles:
			t[0].fit2()

		#print(self.tiles)

	def gaussian(self, img, sigma):
		
		self.shape = img.shape
		h, w = self.shape

		tile_size_h = int((h + args.tiles - 1) / args.tiles)
		tile_size_w = int((w + args.tiles - 1) / args.tiles)
		tile_overlap = int(tile_size_h * args.tile_overlap)
		self.tile_overlap = tile_overlap
		
		self.tiles = []
		for y in range(0, h, tile_size_h):
			for x in range(0, w, tile_size_w):
				ul = (y, x)
				lr = (min(y + tile_size_h, h), min(x + tile_size_w, w))
				
				tile_overlap_e = tile_overlap
				eul = (max(0, y - tile_overlap_e), max(0, x - tile_overlap_e))
				elr = (min(y + tile_size_h + tile_overlap_e, h), min(x + tile_size_w + tile_overlap_e, w))
				
				psf = Psf()
				psf.gaussian(img[eul[0] : elr[0], eul[1]: elr[1]], sigma)
				self.tiles.append((psf, ul, lr, eul, elr))
		
	def apply(self, img, flip = False):
		if self.shape != img.shape:
			raise ValueError("psf shape differs")
	
	
		res = np.zeros_like(img)
		#mask = np.zeros_like(img)
		
		for psf, ul, lr, eul, elr in self.tiles:
			t_res = psf.apply(img[eul[0] : elr[0], eul[1]: elr[1]], flip)
			t_mask = np.zeros_like(t_res)
			t_mask[ul[0] - eul[0]:lr[0] - eul[0], ul[1] - eul[1]:lr[1] - eul[1]] = 1
			t_mask = cv2.blur(t_mask, (self.tile_overlap - 1, self.tile_overlap - 1))
			res[eul[0] : elr[0], eul[1]: elr[1]] += t_res * t_mask
			#mask[eul[0] : elr[0], eul[1]: elr[1]] += t_mask
			#cv2t.imshow("tile", mask)
			#cv2t.waitKey(0)
		return res
		
	def update(self, cor_psf, dat, res):
		for psf, ul, lr, eul, elr in self.tiles:
			t_cor_psf = cor_psf[eul[0] : elr[0], eul[1]: elr[1]]
			t_dat = dat[eul[0] : elr[0], eul[1]: elr[1]]
			t_res = res[eul[0] : elr[0], eul[1]: elr[1]]
			t_mask = np.zeros_like(t_res)
			t_mask[ul[0] - eul[0]:lr[0] - eul[0], ul[1] - eul[1]:lr[1] - eul[1]] = 1
			t_mask = cv2.blur(t_mask, (self.tile_overlap - 1, self.tile_overlap - 1))
			t_dat *= t_mask
			psf.update(t_cor_psf, t_dat, t_res)
	
	def interpolate(self, s):
		for psf, ul, lr, eul, elr in self.tiles:
			psf.interpolate(s)

	def hfr(self):
		hfrlist = []
		for psf, ul, lr, eul, elr in self.tiles:
			hfrlist.append(psf.hfr())
		return np.median(hfrlist)
	

def testPsf(shape, psf):
	test = np.zeros(shape, dtype = np.float64)
	test[:: args.diameter * 2, :: args.diameter * 2] = 1
	test = psf.apply(test)
	return test


def get_hfr(img, ptlist):
	hf = 0.0
	img = np.array(img, dtype = np.float32)
	for (y, x, v, h, mask, low) in ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		psf -= low
		psf = np.abs(psf)
		psf[np.where(mask == 0)] = 0
		
		hf += hfr(psf)
	return hf / len(ptlist)

def up_erode(img, r):
	size = (img.shape[1], img.shape[0])
	up = cv2.pyrUp(img)
	up = cv2.erode(up, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (r,r)))
	return cv2.pyrDown(up, dstsize = size)

def up_dilate(img, r):
	size = (img.shape[1], img.shape[0])
	up = cv2.pyrUp(img)
	up = cv2.dilate(up, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (r,r)))
	return cv2.pyrDown(up, dstsize = size)

def mean_clip(src):
	avg, stddev = cv2.meanStdDev(src)
	for i in range(0, 3):
		mask = cv2.compare(src, avg + stddev ** 2 * 4, cv2.CMP_LE)
		avg, stddev = cv2.meanStdDev(src, mask=mask)
	
	avg = float(avg)
	print("mean_{}: {}".format(src.shape, avg))
	return avg


class reg_pm_2:
	def step1(self, res_a, l, m = None):
		g = []
		try:
			l = np.pad(l, ((1, 1), (1, 1)), 'edge')
			l = np.mean([l[:-1,:-1], l[:-1,1:], l[1:,:-1], l[1:,1:]], axis = 0)
		except:
			pass
		
		res = np.mean(res_a, axis = 0)
		p_res = np.pad(res, ((1, 1), (1, 1)), 'edge')
		
		#p_res -= cv2.GaussianBlur(p_res, (11,11), 0)
		
		grad_x = np.diff(p_res, axis = 1)
		grad_xm = np.mean([grad_x[0:-1, :], grad_x[1:, :]], axis = 0)
		grad_y = np.diff(p_res, axis = 0)
		grad_ym = np.mean([grad_y[:, 0:-1], grad_y[:, 1:]], axis = 0)
	
		lap = cv2.GaussianBlur(res, (7,7), 0) - res
		lap = np.pad(lap, ((1, 1), (1, 1)), 'edge')
		lap = np.mean([lap[:-1,:-1], lap[:-1,1:], lap[1:,:-1], lap[1:,1:]], axis = 0)
		lap[np.where(lap > 0)] = 0
			
			
		g = grad_xm ** 2 + grad_ym ** 2 + lap ** 2 * 2

		##g /= l ** 2
		#g = 1 / ( 1 + g ** 0.5) #!
		##g = 1 / ( 1 + g)
		#g = g / ( 1 + g)**2
		#g = g**0.5 / ( 1 + g)
		#g /= starprot

		##g = cv2.medianBlur(g, 3)
		#g = cv2.GaussianBlur(g, (3,3), 0)
		#g = cv2.dilate(g, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		
		#g = l ** 2 / ((g ** 0.5 + l) * (g ** 0.5 + l / 10))
		self.m = m
		if self.m is None:
			self.m = mean_clip(g)

		l = l ** 2 * self.m
		g = 1. / (1. + (g / l) ** 1)
		#g = cv2.GaussianBlur(g, (3,3), 0)
		
		cv2t.imshow("g2_%d" % g.shape[1], normalize(g))
		self.gx = np.mean([g[1:, 1:-1], g[:-1, 1:-1]], axis = 0)
		self.gy = np.mean([g[1:-1, 1:], g[1:-1, :-1]], axis = 0)

	def step2(self, c):
		grad_x = np.diff(c, axis = 1)
		grad_y = np.diff(c, axis = 0)
		grad_xg = grad_x * self.gx
		grad_yg = grad_y * self.gy


		del grad_x
		del grad_y
	
		grad_xg2 = np.diff(grad_xg, axis = 1)
	
		grad_yg2 = np.diff(grad_yg, axis = 0)
		del grad_xg
		del grad_yg
	
		reg = np.zeros_like(c)
		reg[:, 1:-1] +=  grad_xg2
		reg[1:-1, :] +=  grad_yg2

		del grad_xg2
		del grad_yg2
		return reg


class reg_pm_4:
	def __init__(self, size = 3):
		self.size = size

	def laplacian(self, img):
		lap = cv2.GaussianBlur(img, (3,3), 0) - img
		#lap = cv2.Laplacian(img, -1, ksize = self.size)
		#if self.size > 3:
		#	lap -= cv2.Laplacian(img, -1, ksize = self.size - 2)
		return lap

	def step1(self, res_a, l):
		g = []
		for res in res_a:
			lap = cv2.GaussianBlur(res, (3,3), 0) - res
			g.append(lap ** 2)
		g = np.mean(g, axis = 0)

		#g = l ** 2 / ((g ** 0.5 + l) * (g ** 0.5 + l / 10))
		l = l ** 2 * mean_clip(g)

		g = 1. / (1. + (g / l))
		g = cv2.medianBlur(g, 3)
		g = cv2.erode(g, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		g = cv2.GaussianBlur(g, (3,3), 0)

		#g = cv2.dilate(g, cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3)))
		cv2t.imshow("g4_%d" % self.size, normalize(g))
		self.g = g

	def step2(self, c):
		lap = self.laplacian(c)
		lap *= self.g
		reg = - self.laplacian(lap)
		return reg

class Pyramid(object):
	def __init__(self, depth = 3, reg = None, l = None):
		if reg is not None:
			depth = len(reg)
			self.l_mul = l
			self.reg = reg
		else:
			self.l_mul = [1.0] * depth
			self.reg = [1.0] * depth
		
		self.depth = depth


	def gaussian_pyr(self, img):
		gp = [img]
		for i in range(self.depth):
			try:
				img = cv2.pyrDown(img)
			except:
				pass
			gp.append(img)
		return gp

	def laplacian_pyr(self, img):
		gp = self.gaussian_pyr(img)
		
		lp = []
		for i in range(self.depth,0,-1):
			size = (gp[i - 1].shape[1], gp[i - 1].shape[0])
			up = cv2.pyrUp(gp[i], dstsize = size)
			lap = cv2.subtract(up, gp[i-1])
			lp.append(lap)
		return lp[::-1]

	def gaussian_pyr_er(self, img):
		gp = [img]
		for i in range(self.depth):
			try:
				img = cv2.GaussianBlur(img, (3,3), 0)
				img = cv2.erode(img, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
				img = cv2.pyrDown(img)
			except:
				pass
			gp.append(img)
		return gp

	def laplacian_pyr_er(self, img):
		gp = self.gaussian_pyr_er(img)
		
		lp = []
		for i in range(self.depth,0,-1):
			size = (gp[i - 1].shape[1], gp[i - 1].shape[0])
			up = cv2.pyrUp(gp[i], dstsize = size)
			lap = cv2.subtract(up, gp[i-1])
			lp.append(lap)
		return lp[::-1]

	def collapse(self, pyr):
		up = pyr[self.depth - 1] * self.reg[self.depth - 1]
		for i in range(self.depth - 2, -1, -1):
			size = (pyr[i].shape[1], pyr[i].shape[0])
			up = cv2.pyrUp(up, dstsize = size)
			up = up + pyr[i] * self.reg[i]
		return up
		

class reg_pm_2_pyr(Pyramid):
	def __init__(self, depth = 3, reg = None, l = None):
		super(reg_pm_2_pyr, self).__init__(depth, reg, l)
		self.m = [1] * self.depth
	
	def step1(self, res_a, l, eval_noise):
		
		l = self.gaussian_pyr(l)
	
		gp = []
		for res in res_a:
			gp.append(self.gaussian_pyr(res))
		
		self.levels = []
		for i, (img, ll, lm) in enumerate(zip(zip(*gp), l, self.l_mul)):
			pm = reg_pm_2()
			
			if eval_noise:
				pm.step1(img, ll * lm)
				self.m[i] = pm.m
			else:
				pm.step1(img, ll * lm, self.m[i])
			self.levels.append(pm)
	
	def step2(self, c):
		gp = self.gaussian_pyr(c)
		resp = []
		for pm, img in zip(self.levels, gp):
			print(pm.gx.shape, img.shape)
			resp.append(pm.step2(img))
		
		
		return self.collapse(resp)
		


class reg_pyr(Pyramid):
	def __init__(self, depth = 3, reg = None, l = None):
		super(reg_pyr, self).__init__(depth, reg, l)
		self.m = [1] * self.depth
	
	def step1(self, res_a, l, eval_noise):
		l = self.gaussian_pyr(l)
		
		lps = []
		res = np.mean(res_a, axis = 0)
		lps.append(self.laplacian_pyr(res))
			
		self.g_lp = []
		for i in range(self.depth):
			g = []
			for j in range(len(lps)):
				lap = lps[j][i]
				
				g.append(lap * lap)
				
			
			g = np.mean(g, axis = 0)
			if eval_noise:
				self.m[i] = mean_clip(g)
			lm = ((l[i] * self.l_mul[i]) ** 2) * self.m[i]

			g = 1. / (1. + (g / lm) ** 1)
			#if i == self.depth - 1:
			#	g = cv2.medianBlur(g, 3)
			#g = cv2.erode(g, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
			#g = cv2.GaussianBlur(g, (3,3), 0)

			#g = cv2.dilate(g, cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3)))
		
			self.g_lp.append(g)
		
		for i, g in enumerate(self.g_lp):
			cv2t.imshow("g_pyr_%d" % i, g)

	def step2(self, c):
		lp = self.laplacian_pyr(c)
		reg_lp = []
		for i in range(self.depth):
			lp[i] *= self.g_lp[i]
			reg_lp.append(lp[i] - cv2.GaussianBlur(lp[i], (3,3), 0))
			#-cv2.Laplacian(lp[i], -1, ksize = 3))
		
		
		return self.collapse(reg_lp)



def average_src(src, white, weights = None):
	sum_src = 0.0
	sum_weights = 0.001
	
	if weights is None:
		weights = [1.0] * len(src)
	
	for i in range(0, len(src)):
		s = np.array(src[i], dtype = np.float32)
		w = np.array(weights[i], dtype = np.float32)
		sum_src = sum_src + s / white[i] * w
		sum_weights = sum_weights + w
	res = sum_src / sum_weights
	res[np.where(sum_weights <= 0.001)] = args.zero / white[0]
	return res, sum_weights

def cluster_exps(exps):
	minv = np.amin(exps)
	maxv = np.amax(exps)
	hist, bins = np.histogram(exps, bins = np.arange(minv - 1.0, maxv + 2.0, 1.0), density=False)
	
	print(hist, bins)
	
	res = []
	while True:
		max_i = np.argmax(hist)
		if hist[max_i] == 0:
			break
		
		low = max(max_i - 1, 0)
		high = min(max_i + 1, len(hist) - 1)
		
		w = np.where((exps >= bins[low]) & (exps < bins[high + 1]))[0]
		res.append(w)
		
		hist[low] = 0
		hist[high] = 0
		hist[max_i] = 0
		print(hist)
	print(res)
	return res
		

def save_output(it = None):
	res_ch = []
	for outc in range(0, outchannels):
		res_ch.append(cv2.multiply(res[outc], 65535.0, dtype = cv2.CV_16UC1))

	outidx = 0
	for i, fn in enumerate(outfiles):
		res_i = []
		for j in range(0, outfiles_c[i]):
			res_i.append(res_ch[outidx])
			outidx += 1
		kwargs = {}
                
		if np.asarray(transp[i]).shape == res[0].shape:
			if len(res_i) == 1:
				kwargs = {'planarconfig': 'contig', 'photometric' : 'minisblack'}
			#res_i.append(transp[i])
		
		res_i = cv2.merge(res_i)
		if it is not None:
			fn = "i%04d_%s" % (it, fn)
		tifffile.imsave(fn, res_i, **kwargs)
		del res_i
	del res_ch


np.set_printoptions(precision=6, linewidth=160)

src = []
src_white = []
psfsrc = []
psfsrc_white = []
imgidx = []
transp = []
weights = []
maxval = []

exps = []
gradient_weight = []

outmap = []

outfiles = []
outfiles_c = []
outchannels = 0


nc = 1
for f in args.outfile.split(','):
	try:
		nc, fn = f.split(':')
		nc = int(nc)
	except:
		fn = f
	outfiles.append(fn)
	outfiles_c.append(nc)
	outchannels += nc

outc_num = [0] * outchannels

outc = 0
for f in args.infile:
	fn = f
	exp = 1.0
	grad_weight = 1.0
	if not os.path.isfile(fn):
		try:
			outc, fn = fn.split(':')
			outc = int(outc)
		except:
			pass

	for fn in fn.split(','):
		if not os.path.isfile(fn):
			try:
				fn, exp_s, grad_weight_s = fn.split('@')
				exp = float(exp_s)
				grad_weight = float(grad_weight_s)
			except: 
				try:
					fn, exp = fn.split('@')
					exp = float(exp)
				except:
					pass
		if not os.path.isfile(fn):
			print(fn, "not found")
			sys.exit(1)
			


		print("Read ", fn)
		img = tifffile.TiffFile(fn).asarray(memmap=True)
		if img is None:
			print('Failed to load fn:', fn)
			sys.exit(1)

		white = np.iinfo(img.dtype).max
		img = np.atleast_3d(img)
		if args.crop is not None:
			img = img[args.crop[0], args.crop[1]]
		h, w, channels = img.shape
		col = [1,1,1,3,3][channels]
	
		transp_c = white
		if channels > col:
			transp_c = img[:,:,col]
		
		#mask = np.amin(img, axis = 2)
		#img = extrapolate_transp(img[:,:,0:col], mask, add = True)
	
		outi = outc
		cidx = []
		for c in range(0, col):
			cidx.append(len(src))
			src.append(img[:,:, c])
			src_white.append(white)
			weights.append(transp_c)
			
			mv = np.amax(cv2.medianBlur(img[:,:, c], 3))
			maxval.append(mv)
		
			outmap.append(outi)
			outc_num[outi] += 1
			outi += 1
		
			exps.append(exp)
			gradient_weight.append(grad_weight)
		imgidx.append(cidx)
		transp.append(transp_c)


exps = np.array(exps, dtype = np.float64)

scales = 2.0 ** exps

scales /= np.amax(scales)
scales *= args.scale

exp_clusters = cluster_exps(exps)

sum_src, sumweights = average_src(src, src_white, weights)

print("sumweights", sumweights)
print("sum_src", sum_src)

if args.psffile:
	for f in [args.psffile]:
		img = tifffile.TiffFile(f).asarray(memmap=True)
		if img is None:
			print('Failed to load fn1:', f)
			sys.exit(1)

		white = np.iinfo(img.dtype).max
		img = np.atleast_3d(img)
		h, w, channels = img.shape
		col = [1,1,1,3,3][channels]

		for c in range(0, col):
			psfsrc.append(img[:,:, c])
			psfsrc_white.append(white)

	sum_psfsrc, sum_psfweights = average_src(psfsrc, psfsrc_white)
else:
	psfsrc = src
	psfsrc_white = src_white
	sum_psfsrc = sum_src



col = len(src)



#s_res = cv2.GaussianBlur(sum_src,(5,5),0)
#s_res = cv2.erode(s_res, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7)))
s_res = sum_src

if args.gaussian == 0.0:
	ptlist = find_ptlist(sum_psfsrc)

	show = normalize(sum_psfsrc ** 0.4)
	for (y, x, v, h, mask, low) in ptlist:
		cv2.circle(show, (int(x),int(y)), 10, (255), 1)
	cv2.imwrite("pts_all.tif", show)

	del sum_psfsrc

	cluster_idx = [None] * col
	cluster_ptlists = []
	for cl_i, cl in enumerate(exp_clusters):
		cl_psfsrc = []
		cl_psfsrc_white = []
		cl_weights = []
		for i in cl:
			cl_psfsrc.append(psfsrc[i])
			cl_psfsrc_white.append(psfsrc_white[i])
			cl_weights.append(weights[i])
			cluster_idx[i] = cl_i

		sum_psfsrc, sum_psfweights = average_src(cl_psfsrc, cl_psfsrc_white, cl_weights)
		cl_ptlist = filter_ptlist(sum_psfsrc, ptlist)

		show = normalize(sum_psfsrc ** 0.4)
		for (y, x, v, h, mask, low) in cl_ptlist:
			cv2.circle(show, (int(x),int(y)), 10, (255), 1)
		cv2.imwrite("pts%d.tif" % cl_i, show)

		del sum_psfsrc
		cluster_ptlists.append(cl_ptlist)


psf = [None] * col
c_ptlists = [None] * col

skipped = [False] * col

res = [None] * outchannels
var = [1.0] * outchannels
reg_prev = [None] * outchannels
kappa = 10.0

try:
	if args.load_psf:
		f = open(args.load_psf, 'rb')
		psf = pickle.load(f)
		f.close()
		for c in range(0, col):
			cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
	else:
		raise IOError
except:
	psf = [None] * col

	def step1(c, lock):
		print("start0  %d" % c)
		psf[c] = TilePsf()
		psfs = np.array(psfsrc[c], dtype = np.float32) / psfsrc_white[c]
		if args.gaussian == 0.0:
			c_ptlist = cluster_ptlists[cluster_idx[i]]
			c_ptlists[c] = set_psf_level(psfs, c_ptlist)
			psf[c].extract(psfs, c_ptlists[c], args.psf_filter_sigma)
			cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
		else:
			psf[c].gaussian(psfs, args.gaussian)


	pfor.pfor(step1, list(range(0, col)))

	if args.save_psf:
		f = open(args.save_psf, 'wb')
		pickle.dump(psf, f)
		f.close()

for c in range(0, outchannels):
	res[c] = cv2.GaussianBlur(s_res, (3,3), 0)

res = np.array(res)


noise = noise_level(sum_src) + 0.00000001
print("noise:", noise * 65535.0)

reg1 = reg_pm_2_pyr(reg = args.reg2, l = args.reg_lambda2)
reg2 = reg_pyr(reg = args.reg4, l = args.reg_lambda4)

#for c in range(0, col):
#	psf[c].interpolate(args.psf_filter_moffat_scale)

it = args.iter

for i in range(0, it):

	print(i)
	if i <= it / 2:
		for c in range(0, col):
			psf[c].interpolate(args.psf_filter_moffat_scale * np.clip(i *  2.0 / it, 0, 1))


	s_res = np.mean(res, axis = 0)
	print("check s_res", np.isnan(s_res).any(), cv2.minMaxLoc(s_res))

	#if i < 10:
	noise = noise_level(s_res) + 0.00000001
	print("noise:", noise * 65535.0)
	
	#starprot = -cv2.Laplacian(s_res, -1, ksize = 5)
	#starprot /= (noise * args.reg_starprot)
	#starprot[np.where(starprot < 1.0)] = 1.0
	
	#starprot = np.pad(starprot, ((1, 1), (1, 1)), 'edge')
	#starprot = np.mean([starprot[:-1,:-1], starprot[:-1,1:], starprot[1:,:-1], starprot[1:,1:]], axis = 0)
	#cv2t.imshow("starprot", normalize(1.0/starprot))


	sum_w = np.zeros_like(res)
	sum_corw = np.zeros_like(res)
	var_next = np.zeros_like(res)

	#reg_weight = 1 + (float(i) / it * args.robustness ** 0.5)**2
	dat_eps = 1.0 / args.robustness**4
	
	rings = []
	for outc in range(0, outchannels):
		r = np.clip(cv2.GaussianBlur(res[outc], (3,3), 0) - res[outc], 0.0, 1.0)
		r = r * 1000000 + 1
		rings.append(r)
	
	def step2(c, lock):
		if skipped[c]:
			return
		print("start2 %d %d" %(i,c))
		kappa = (it - i) / it * 10 + 2
		outc = outmap[c]

		b_res = psf[c].apply(res[outc])
		scaled_src = (np.array(src[c], dtype=np.float32) * scales[c] + args.zero * (1.0 - scales[c])) / src_white[c]

		weight = np.empty_like(src[c], dtype=np.float32)
		weight[:, :] = weights[c] / (scales[c] ** np.clip(i * 2.0 / it, 0.0, 1))
		
		gr = args.gradient_radius
		w2 = cv2.blur(weight, (gr,gr)) / src_white[c]
		w2 = cv2.blur(w2, (gr,gr))
		w2 *= w2
		weight *= w2
		del w2
		
		where_over = np.where((src[c] > maxval[c] * args.overexp) & (scaled_src < b_res))
		weight[where_over] /= 1.0 + (src[c][where_over] - maxval[c] * args.overexp) / (src_white[c] / 1000.0)
		
		scaled_src = (np.array(src[c], dtype=np.float32) * scales[c] + args.zero * (1.0 - scales[c])) / src_white[c]
		scaled_src[np.where(weight == 0)] = args.zero / src_white[c]
		
		dif = scaled_src - b_res
		mean_w = 0.0000001 / (0.0000001 + dif * dif) * weight

		gw = gradient_weight[c]
		
		dat = mean_w
		
		#b_rings = psf[c].apply(rings[outc])

		for ii in range(2):
			difw = dif * dat
			difw = cv2.blur(difw, (gr,gr))
			difw = cv2.blur(difw, (gr,gr))
			difw = cv2.blur(difw, (gr,gr))
			difw = cv2.blur(difw, (gr,gr))
		
			mean_w = cv2.blur(mean_w, (gr,gr))
			mean_w = cv2.blur(mean_w, (gr,gr))
			mean_w = cv2.blur(mean_w, (gr,gr))
			mean_w = cv2.blur(mean_w, (gr,gr))
		
			difw = cv2.divide(difw, mean_w)

			src_hp = scaled_src - difw
			cor_hp = cv2.divide(src_hp, b_res)
			cor_hp[np.where(cor_hp < 0.00001)] = 0.00001
			
		
			dat = b_res - (src_hp) * (1.0 - np.log(cor_hp))

			dat = dat * dat
			
		
			if ii == 1:
				with lock:
					var_next[outc] += dat
				clip = np.where(dat > var[outc] * kappa * kappa)
				
		
			dat = (dat + dat_eps) ** -0.25
		
			dat *= weight / src_white[c]
		
		dat[clip] = 0
		#dat *= b_rings
		#if c == 1 or c == 300:
		#	cv2t.imshow("b_rings%d" % c, normalize(b_rings))
		#del(b_rings)
		
		
		cor = cv2.divide(scaled_src - difw * (1.0 - gw), b_res)
		cor[np.where(cor < 0.00001)] = 0.00001
		cor_psf = cor

		
		
		del b_res
		
		try:
			cor_mean = np.average(cor, weights = dat)
		except:
			cor_mean = 1.0
		if outc_num[outc] > 1:
			scales[c] /= cor_mean ** 0.5

		with lock:
			print("cor mean", cor_mean)


		corw = psf[c].apply(cv2.multiply(dat, cor), flip = True)
		w =  psf[c].apply(dat, flip = True)
		#cor = psf.apply(cor, flip = True)
		corw[np.where(corw < 0.0)] = 0.0
		w[np.where(w < 0.0)] = 0.0

		with lock:
			#cv2.imwrite("reg_p%d_%d.tif" % (c, i), normalize(reg_p))
#			print("check res", np.isnan(res[c]).any(), cv2.minMaxLoc(res[c]))
		
#			print("check reg_p", np.isnan(reg_p).any(), cv2.minMaxLoc(reg_p))
#			print("check reg_m", np.isnan(reg_m).any(), cv2.minMaxLoc(reg_m))
			print("check dat", np.isnan(dat).any(), cv2.minMaxLoc(dat))
			print("check w", np.isnan(w).any(), cv2.minMaxLoc(w))
			print("check corw", np.isnan(corw).any(), cv2.minMaxLoc(corw))

			sum_w[outc] += w
			sum_corw[outc] += corw
		
		if c < 3:
			cv2t.imshow("dat%d" % c, normalize(-dat**0.5))
		
		if c == 1 or c == 300:
			cv2t.imshow("dif%d" % c, normalize(difw))
		
				
		if args.update_iter > 0 and i > args.update_iter:
			psf[c].update(cor_psf, dat, res[outc])
		
		print("end2 %d %d" %(i,c))
	pfor.pfor(step2, list(range(0, col)) if i % 2 == 0 else reversed(list(range(0, col))))
	
	print("scales", scales)
	
	var = var_next

	norm_w = []
	for sw in sum_w:
		norm_w.append(sw / np.median(sw))
	norm_w = 1.0 / np.mean(norm_w, axis = 0)
	
	norm_w = cv2.dilate(norm_w, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (args.weight_dilate * 2 + 1, args.weight_dilate * 2 + 1)))
	norm_w = np.clip(norm_w, 1.0, 10.0)
	norm_w = cv2.GaussianBlur(norm_w, (args.weight_dilate * 2 + 1, args.weight_dilate * 2 + 1), 0)
		
	cv2t.imshow("norm_w", norm_w / 10.0)

	reg1.step1(res, norm_w ** 0, i < args.lambda_eval_iter)
	#reg2 = reg_pm_4(size = 1)
	#reg2.step1(res, args.reg_lambda * norm_w)
	reg2.step1(res, norm_w ** 0, i < args.lambda_eval_iter)

	for outc in range(0, outchannels):
		var[outc] /= outc_num[outc]
		print("check rings", np.isnan(rings[outc]).any(), cv2.minMaxLoc(rings[outc]))

		print("check res_pre", np.isnan(res[outc]).any(), cv2.minMaxLoc(res[outc]))

		#cor = cv2.divide(sum_corw[outc], sum_w[outc])

		#res[outc] *= cor
	
	
		#reg_weight = args.reg * min(float(i) / (it * 0.3), 1)
		reg = reg1.step2(res[outc]) + reg2.step2(res[outc])
		print("check reg1", np.isnan(reg).any(), cv2.minMaxLoc(reg))
		#print("check reg2", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		missing = np.where(sum_w[outc] < 1.0)
		sum_w[outc][missing] = 1

		#reg = cv2.divide(reg, sum_w[outc])
		#reg *= np.mean(sum_w[outc])
		print("check reg3", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		#mean, stddev = cv2.meanStdDev(reg)
		#stddev = float(stddev)
		#reg = np.clip(reg, -stddev * 3, stddev * 3)

		
		#hp = cv2.Laplacian(res[outc], -1, ksize = 7)
		#coefs = np.linalg.lstsq(np.array([reg.ravel()]).T, hp.ravel().T)[0]
		#print("reg fit ", coefs)
		
		
		#reg = cv2.divide(reg, np.clip(res[outc], 1024.0/65535.0, 1))

		#print("check reg4", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		reg[missing] = 0
		print("check reg5", np.isnan(reg).any(), cv2.minMaxLoc(reg))


		#reg[np.where(src[c] > 0.95)] /= 1000
	
		#reg = cv2.GaussianBlur(reg, (3,3), 0.6)
		#if i > 0:
		#	reg = reg * 0.1 + reg_prev[outc] * 0.9
		#	reg_prev[outc] = reg
		#else:
		#	reg_prev[outc] = (reg * 0.1)
		
		
		
		#print reg
		reg *= (1.0 + args.reg_plus * (np.clip(norm_w, 1 , 3) - 1.0) / 2.0)
		reg_p = np.array(reg)
		reg_p[np.where(reg < 0.)] = 0.
		reg_m = reg - reg_p
		reg = reg_m + reg_p
	
		#res[outc] *= cv2.divide(1 + reg_p, 1 - reg_m)

		#cor = cv2.divide(sum_corw[outc] + reg_p, sum_w[outc] - reg_m)
		cor = cv2.divide(sum_corw[outc], sum_w[outc])
		cor[missing] = 1.0
		cor[np.where(cor < 0.01)] = 0.01
		cor[np.where(cor > 100.)] = 100.

		res[outc] *= cor
		res[outc] += reg


		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(res[outc])
		maxVal = min(maxVal, 1.0)
		avg, stddev = cv2.meanStdDev(res[outc])
		
		floodmask = np.zeros((res[outc].shape[0] + 2, res[outc].shape[1] + 2), dtype=np.uint8)
		cv2.floodFill(res[outc], floodmask, minLoc, 2, loDiff = 0, upDiff = (maxVal - minVal) * args.top_thres, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY + cv2.FLOODFILL_FIXED_RANGE)
		floodmask = floodmask[1:-1, 1:-1]
		#cv2t.imshow("fm%d" % outc, normalize(floodmask))
		top = cv2.dilate(res[outc], cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)))
		top = cv2.erode(top, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)))
		top[floodmask > 0] = 0
		cv2t.imshow("top%d" % outc, normalize(top))
		res[outc] = np.maximum(res[outc], top)

		if args.erode > 0 and  i < args.erode_iter:
			erod = up_erode(res[outc], 3)
			res[outc] = erod * args.erode + res[outc] * (1.0 - args.erode)


		if i < args.blur_iter:
			res[outc] = cv2.GaussianBlur(res[outc], (17, 17), args.blur_sigma * (1.0 - i / args.blur_iter))

		print("check res", np.isnan(res[outc]).any(), cv2.minMaxLoc(res[outc]))

		print("check reg_p", np.isnan(reg_p).any(), cv2.minMaxLoc(reg_p))
		print("check reg_m", np.isnan(reg_m).any(), cv2.minMaxLoc(reg_m))
		

		cv2t.imshow("reg_p%d" % outc, normalize(reg_p))
		cv2t.imshow("reg_m%d" % outc, normalize(-reg_m))
		cv2t.imshow("res%d" % outc, normalize(np.clip(res[outc] - 1010/65535.0,10/65535.0,1)** args.show_gamma))

#		if args.gaussian == 0.0:
#			curhfr = get_hfr(res[outc], ptlist)
#			print("hfr", curhfr)
			#if i < 3 and curhfr > 2:
			#	res = cv2.erode(res, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))

	if args.update_iter > 0:
		hfr_list = []
		for c in range(0, col):
			hfr_list.append(psf[c].hfr())

		print("res_hfr", i, hfr_list)
		
#		if i == 150:
#			s_hfrlist = sorted(hfr_list)
#			thr = s_hfrlist[col / 8]
#			for c in range(0, col):
#				skipped[c] = hfr_list[c] > thr
#				cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
#			print "hfr thr", thr
#			print skipped
			
	save_output(i)
	

	cv2t.waitKey(1)
	gc.collect()
	
#for outc in range(0, outchannels):
#	if args.gaussian == 0.0:
#		psf = TilePsf()
#		pts = set_psf_level(res[outc], ptlist)
#		psf.extract(res[outc], pts, 0.01)
#		cv2.imwrite("testpsf%d_res.tif" % (outc), normalize(testPsf(src[outc].shape, psf)))
	

save_output()

cv2t.waitKey(1000)
