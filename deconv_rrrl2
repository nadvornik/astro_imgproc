#!/usr/bin/env python3

# Copyright (C) 2017 Vladimir Nadvornik
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.


import tifffile
import numpy as np
import cv2
import sys
import os
import argparse
import pfor
import gc
import pickle
import time

from astro_utils import noise_level, poly_bg, poly_res, poly_array,  extrapolate_transp
from centroid import centroid, sym_center

from scipy.optimize import curve_fit

def crop_param(s):
	try:
		if s is None:
			return None
		x1,x2,y1,y2 = s.split(',')
		return (slice(int(y1),int(y2)), slice(int(x1),int(x2)))
	except:
    		raise argparse.ArgumentTypeError("Filter param must be r,s")


parser = argparse.ArgumentParser()
parser.add_argument("outfile",
                    help="output tiff file")
parser.add_argument("infile", nargs='+',
                    help="input tiff file")

parser.add_argument("--psffile",
                    help="psf tiff file if different from infile")

parser.add_argument("--iter", type=int, default=10,
                    help="number of iteration")
parser.add_argument("--diameter", type=int, default=15,
                    help="psf diameter")
parser.add_argument("--tiles", type=int, default=4,
                    help="number of tiles NxN")
parser.add_argument('--var-psf', action='store_true',
                    help="variable psf")

parser.add_argument('--update-scales', action='store_true',
                    help="update scales")

parser.add_argument("--psf-filter-sigma-res", type=float, default=1.2,
                    help="psf filter")
parser.add_argument("--psf-filter-sigma", type=float, default=0.5,
                    help="psf filter final sigma")
parser.add_argument("--psf-filter-moffat-scale", type=float, default=1,
                    help="psf filter moffat scale")

parser.add_argument("--update-iter", type=int, default=0,
                    help="start updating at iteration i")
parser.add_argument("--update-accel", type=float, default=20,
                    help="update accel")

parser.add_argument("--blur-iter", type=int, default=0,
                    help="start updating at iteration i")
parser.add_argument("--blur-sigma", type=float, default=2,
                    help="update accel")

parser.add_argument("--reg2", type=float, default=[0.1], nargs = '+',
                    help="regularization2")
parser.add_argument("--reg-lambda2", type=float, default=[2.0], nargs = '+',
                    help="lambda2")
parser.add_argument("--reg4", type=float, default=[0.1], nargs = '+',
                    help="regularization4")
parser.add_argument("--reg-lambda4", type=float, default=[2.0], nargs = '+',
                    help="lambda4")
parser.add_argument("--regf", type=float, default=[0.1], nargs = '+',
                    help="regularization flatten")
parser.add_argument("--reg-lambdaf", type=float, default=[2.0], nargs = '+',
                    help="lambda f")
parser.add_argument("--lambda-eval-iter", type=int, default=1000,
                    help="stop updating lambda at iteration i")
parser.add_argument("--reg-plus", type=float, default=1,
                    help="reg plus")

parser.add_argument("--reg-mode", default='openclose',
                    help="openclose open close dilate erode modian normal")


parser.add_argument("--erode", type=float, default=0,
                    help="erode accel")
parser.add_argument("--erode-iter", type=int, default=0,
                    help="stop erode at iteration i")

parser.add_argument("--top-thres", type=float, default=0.5,
                    help="top-thres")

parser.add_argument("--robustness", type=float, default=1000,
                    help="robustness")

parser.add_argument("--dering", type=float, default=0.9,
                    help="deringing")


parser.add_argument("--gaussian", type=float, default=0.0,
                    help="blind with gaussian")

parser.add_argument("--gradient-radius", type=int, default=300,
                    help="gradient radius")

parser.add_argument("--crop", type=crop_param, default=None,
                    help="crop x1,x2,y1,y2")

parser.add_argument("--scale", type=float, default=1,
                    help="output scale")

parser.add_argument("--zero", type=float, default=1024,
                    help="zero level")


parser.add_argument("--wb", type=float, default=[1.0], nargs = '+',
                    help="white balance")

parser.add_argument("--show-gamma", type=float, default=0.1,
                    help="display gamma")

parser.add_argument("--overexp", type=float, default=0.8,
                    help="overexp level")

parser.add_argument("--tile-overlap", type=float, default=0.25,
                    help="tile overlap")

parser.add_argument("--weight-dilate", type=int, default=2,
                    help="weight dilate")

parser.add_argument("--save-psf",
                    help="save psf")
parser.add_argument("--load-psf",
                    help="load psf")

parser.add_argument("--test-ptlist", action='store_true',
                    help="test ptlist")

args = parser.parse_args()

while len(args.reg2) < len(args.reg_lambda2):
	args.reg2.append(args.reg2[-1])
while len(args.reg_lambda2) < len(args.reg2):
	args.reg_lambda2.append(args.reg_lambda2[-1])
while len(args.reg4) < len(args.reg_lambda4):
	args.reg4.append(args.reg4[-1])
while len(args.reg_lambda4) < len(args.reg4):
	args.reg_lambda4.append(args.reg_lambda4[-1])
while len(args.regf) < len(args.reg_lambdaf):
	args.regf.append(args.regf[-1])
while len(args.reg_lambdaf) < len(args.regf):
	args.reg_lambdaf.append(args.reg_lambdaf[-1])


def normalize(img):
        dst = np.empty_like(img)
        return cv2.normalize(img, dst, alpha = 0, beta = 255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)


hfr_size = None
hfr_mat_mask = None
hfr_mat = None
xsize_mat = None
ysize_mat = None
d1size_mat = None
d2size_mat = None

def set_htr_size(diameter):
	global hfr_size
	global hfr_mat_mask
	global hfr_mat
	global xsize_mat
	global ysize_mat
	global d1size_mat
	global d2size_mat
	
	hfr_size = diameter
	hfr_mat_mask = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (hfr_size * 2 + 1, hfr_size * 2 + 1))
	hfr_mat = cv2.multiply(np.array([[(x**2 + y**2)**0.5 for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)
	xsize_mat = cv2.multiply(np.array([[ abs(x) for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)
	ysize_mat = cv2.multiply(np.array([[ abs(y) for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)
	d1size_mat = cv2.multiply(np.array([[ abs(x + y) for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)
	d2size_mat = cv2.multiply(np.array([[ abs(x - y) for x in range(-hfr_size, hfr_size + 1) ] for y in range(-hfr_size, hfr_size + 1) ], dtype=np.float), hfr_mat_mask, dtype=cv2.CV_32FC1)

def hfr(a , mat = None):
	if mat is None:
		mat = hfr_mat
	s = cv2.sumElems(cv2.multiply(a,  hfr_mat_mask, dtype=cv2.CV_32FC1))[0]
	if s == 0.0:
		return hfr_size
	r = cv2.sumElems(cv2.multiply(a,  mat, dtype=cv2.CV_32FC1))[0] / s
	return r

def poly_array2(X, Y):
	res = np.empty([X.shape[0], 4])
	res[:, 0] = 1
	res[:, 1] = X ** 2
	res[:, 2] = Y ** 2
	res[:, 3] = Y * X

	return res



def find_ptlist(img):
	kernel = hfr_mat_mask #np.ones((args.diameter,args.diameter),np.uint8)
	img = np.array(img, dtype=np.float32, copy=True)
	bl = cv2.GaussianBlur(img,(5, 5),0)
	dil = cv2.dilate(bl, kernel)

	cmpmax = cv2.compare(bl, dil, cv2.CMP_GE)
	
	

	#er = cv2.erode(bl, kernel)
	#bg = cv2.GaussianBlur(er,(19, 19),0)
	#img -= bg
	#img[np.where(img < 0)] = 0

	sigma = noise_level(img)
	cmpmax[np.where(bl <= sigma * 10)] = 0
	
	cv2t.imshow("cmpmax", normalize(cmpmax))

	ptlist = [(y, x) for (y, x) in zip(*cmpmax.nonzero())]

	return ptlist

def psf_bg_w(psf):

	bg = np.median(psf)
	mask = np.zeros_like(psf, dtype=np.uint8)
	mask[psf < bg] = 255

	for i in range(10):
		bg, stddev = cv2.meanStdDev(psf, mask = mask)
		mask = np.zeros_like(psf, dtype=np.uint8)
		mask[psf < bg + 2 * stddev] = 255

    
	psf2  = psf - bg
	w = np.sum(psf2)
	
	return bg, w


def fix_hfr(v, hfr, it):
	A0 = np.ones((len(v), 3))
	A0[:,0] = v
	A0[:,2] = 1.0 / v
	W0 = v ** 0.5
	hfr0 = hfr
	A = A0
	W = W0
	print()
	for i in range(0, it):
		c = np.linalg.lstsq(A * W[:, np.newaxis], hfr * W)[0]
		print(c)
		fit =  np.dot(A, c)
		d2 = (hfr - fit) ** 2
		s2 = np.average(d2)
		
		keep=np.where((d2 < s2 * 10) | (hfr < fit))
		A = A0[keep]
		hfr = hfr0[keep]
		W = W0[keep]
	return c[0:2]

def filter_ptlist(img, i_ptlist, debug=False):
	minv = 64 / 65535.0

	maxval = np.max(img)

	(height,width) = img.shape
	hfrlist = []
	ptlist = []

	for (y, x) in i_ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		
		bl = cv2.GaussianBlur(cv2.medianBlur(psf, 5), (7, 7), 0)
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl)
		
		if maxVal > maxval * 0.9:
			continue

		(xc, yc) = centroid(psf)
		#(xc, yc) = (0, 0)
		
		bg, w = psf_bg_w(psf)

		if maxVal - bg < minv:
			continue

		psf2 = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x + xc, y + yc))
		
		bg, w = psf_bg_w(psf2)
		
		if w <= 0:
			continue
		
		psf2 -= bg
		#psf2 = np.abs(psf2)
		
		hf = []
		skip = False
		for mat in [hfr_mat, xsize_mat, ysize_mat, d1size_mat, d2size_mat]:
			h = hfr(psf2, mat)
			if h <= 0:
				skip = True
				break
			hf.append(h)
		if skip or hf[0] > args.diameter * 0.5:
			continue
		hf.append(xc)
		hf.append(yc)
		#w = max(0, maxVal - bg)

		hfrlist.append([y, x, w] + hf)
		ptlist.append((y, x))

	hfrlist = np.array(hfrlist)
	
	tile_n = np.empty((len(hfrlist),), dtype=np.int)
	tiles = args.tiles ** 2
	tile_h = float(height) / args.tiles
	tile_w = float(width) / args.tiles
	
	for i in range(0, args.tiles):
		for j in range(0, args.tiles):
			tile_n[(hfrlist[:, 0] >= i * tile_h) & (hfrlist[:, 0] < (i + 1) * tile_h) 
			     & (hfrlist[:, 1] >= j * tile_w) & (hfrlist[:, 1] < (j + 1) * tile_w)] = i * args.tiles + j 
	
	#sigma = 10
	keep_all = None

	for t in range(0, tiles):
		
		tile_mask = (tile_n == t)
		if not np.any(tile_mask):
			continue
		avg = np.median(hfrlist[tile_mask,2])
		print("tile avg", t, np.log(avg))

		keep = (hfrlist[:,2] >= avg) & tile_mask
		if not np.any(tile_mask):
			continue
		
		for i in range(0, 10):
			med = np.average(hfrlist[keep, 3], weights = hfrlist[keep, 2])
			sigma2 = np.average((hfrlist[keep, 3] - med)**2, weights = hfrlist[keep, 2])
			sigma2 = max(sigma2, 0.1)
			print("m s", med, sigma2)
			keep = (hfrlist[:, 3] <= med + sigma2**0.5 * 3)  & tile_mask
		#if sigma2 > 6:
		#	continue

		if keep_all is None:
			keep_all = keep
		else:
			keep_all = keep_all | keep

	keep_all = np.where(keep_all)
	hfrlist = hfrlist[keep_all]
	ptlist = [ptlist[i]  for i in keep_all[0]]


	if debug:
		print("plot")
		import matplotlib.pyplot as plt
		
		p = hfrlist#[hfrlist[:, 2] > 20]
		x = p[:, 2]
		y = p[:, 3]# / p[:, 3]
		
		xm = np.amax(x)
		for i in range(100, 100):
			m, c = fix_hfr(x, y, i)
			print(m,c, xm)
			plt.plot([0, xm], [c, c + xm * m], 'b-')

		plt.plot(np.log(x), y, 'ro')
		plt.show()
#	print(hfrlist)
#	print(ptlist)

	Y = hfrlist[:,0]
	X = hfrlist[:,1]
	
	achar0 = np.array(hfrlist[:, 3 :])
	
	#achar0[:, 0 : 4] /= hfrlist[:, 3][:, np.newaxis]
	
	Y = (Y / height * 2.0) - 1.0
	X = (X / width * 2.0) - 1.0
	
	A0 = poly_array(X, Y, 3)
	
	W = np.array(hfrlist[:,2])


	W /= np.amax(W)
	W = W * (1.0 - W)
	W **= 0.5
	
	Ws = np.sqrt(W)
	
	A0w = A0 * Ws[:,np.newaxis]
	
	achar0w = achar0 * Ws[:,np.newaxis]
	
	achar = achar0
	A = A0
	
	acharw = achar0w
	Aw = A0w
	
	nchar = len(achar0[0])
	
	char_sigma2 = [10000.0] * nchar
	char_coef = [None] * nchar
	char_fit0 = [None] * nchar
	
	for i in range(0, 30):
		for j in range(0, nchar):
			char_coef[j] = np.linalg.lstsq(Aw, acharw[:, j])[0]
			char_fit = np.dot(A, char_coef[j])
		
			#hfr_sigma2 = np.average((ahfr - hfr_fit)**2, weights = WW)
			char_sigma2[j] = max(np.average((achar[:, j] - char_fit)**2), 0.1)
			
			kappa = 6

			char_fit0[j] = np.dot(A0, char_coef[j])
			
			
			keep = ((achar0[:, j] - char_fit0[j])**2 <= char_sigma2[j] * kappa)
			if j == 0:
				gkeep = keep
			else:
				gkeep = gkeep & keep
		
		gkeep = np.where(gkeep)

		#if i == 20:
		#	A0 = poly_array(X, Y, 5)
		#	A0w = A0 * Ws[:,np.newaxis]
		
		A = A0[gkeep]
		achar = achar0[gkeep]

		Aw = A0w[gkeep]
		acharw = achar0w[gkeep]
		
		print("gsigma2", char_sigma2, 'len', len(achar), char_coef)
	

	if debug:
		print("plot")
		import matplotlib.pyplot as plt
		
		p = hfrlist[gkeep]#[hfrlist[:, 2] > 20]
		x = p[:, 2]
		y = p[:, 3]# / p[:, 3]
		
		xm = np.amax(x)
		for i in range(100, 100):
			m, c = fix_hfr(x, y, i)
			print(m,c, xm)
			plt.plot([0, xm], [c, c + xm * m], 'b-')

		plt.plot(np.log(x), y, 'ro')
		plt.show()


	print(gkeep)
	ptlist = [ptlist[i]  for i in gkeep[0]]


	if debug:
		show = normalize(img ** 0.4)
		for (y, x) in ptlist:
			cv2.circle(show, (int(x),int(y)), 10, (255), 1)
		cv2.imwrite("pts_t.tif", show)

	return ptlist
	

def get_psf_list(img, ptlist, over):
	img = np.array(img, dtype=np.float32)
	
	psflist = []
	for (y, x) in ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		if np.amax(psf) > over:
			continue

		psflist.append(psf)
	return psflist


def rl_simple(src, psf, it):
	src = np.array(src, dtype=np.float64)
	res = np.ones_like(src)
	for i in range(0, it):
		b_res = psf.apply(res)
		cor = cv2.divide(src, b_res)
		cor[np.where(cor < 0.00001)] = 0.00001
		cor = psf.apply(cor, flip = True)
		res *= cor
	return res


def rrrl_simple(src, psf, it):
	psf_zero = 0.001
	scales = np.ones((len(src),), dtype=np.float64)
	weights = np.ones((len(src),), dtype=np.float64)
	for i in range(len(src)):
		bg, w = psf_bg_w(src[i])
		#bl = cv2.GaussianBlur(cv2.medianBlur(src[i], 5), (7, 7), 0)
		#minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl)
		
		#src[i] -= minVal - psf_zero
		#scales[i] = 1 / (maxVal + 0.00000000001 - minVal) 
		#weights[i] = (maxVal - minVal) #** 2
		
		if w < 0:
			w = 0
		src[i] -= bg - psf_zero
		scales[i] = 1 / (w + 0.00000000001)
		weights[i] = w ** 2
		
		
	src = np.atleast_3d(src)
	src[np.where(src < 0)] = 0
	
	res = np.mean(src, axis = 0)
	res = cv2.GaussianBlur(res, (5,5), 0)
	
	
	for i in range(0, it):
		kappa = (it - i) / it * 10 + 2
		b_res = psf.apply(res)
		b_res[np.where(b_res < 0.0000001)] = 0.0000001
		
		sum_w = np.zeros_like(res)
		sum_corw = np.zeros_like(res)
		
		scaled_src = src * scales[:, None, None] + psf_zero * (1.0 - scales[:, None, None])
		
		cor = scaled_src / b_res[None, :, :]
		cor[np.where(cor < 0.00001)] = 0.00001
		
		dat = b_res[None, :, :] - scaled_src * (1.0 - np.log(cor))
		dat = dat * dat
		
		var = np.mean(dat, axis = 0)
		clip = np.where(dat > (var * kappa**2)[None, :, :])
		
		
		dat = (dat + 1.0 / 10000.0**4) ** -0.25 * weights[:, None, None]
		
		dat[clip] = 0.0
		
		for c in range(0, len(src)):
			#cor_mean = np.average(cor[c], weights = dat[c] + 0.0000001)
			#scales[c] /= cor_mean

			corw = psf.apply(cv2.multiply(dat[c], cor[c]), flip = True)
			w =  psf.apply(dat[c], flip = True)

			corw[np.where(corw < 0.0)] = 0.0
			w[np.where(w < 0.0)] = 0.0

			sum_w += w
			sum_corw += corw
		
		cor = cv2.divide(sum_corw, sum_w)
		res *= cor
	#print(scales)
	res -= psf_zero
	res[np.where(res < 0)] = 0
	
	for c in range(0,len(src)):
		weights[c] = np.mean(dat[c])
	
	target = np.average(scaled_src, axis = 0, weights = weights)
	
	return res, target
		



class PsfGauss:
	def __init__(self, size, sigma):
		self.size = size
		self.sigma = sigma
	
	def apply(self, img, flip = False):
		return cv2.GaussianBlur(img, (self.size, self.size), self.sigma)

class PsfMoffat:
	def __init__(self, size, alpha = 1, beta=4.765, psf = None, residual = None):
		self.size = size
		self.mx = (size - 1) / 2.0
		self.my = (size - 1) / 2.0
		
		if psf is not None:
			self.fit(psf, residual)
		else:
			self.set(alpha, beta)

	def show(self, name, psf, residual, moffat):
		h = 4
		w = len(psf)
		img = np.zeros((h * self.size, w * self.size), dtype = np.uint8)
		def show1(x, y, i1):
			img[y * self.size : (y+1) * self.size, x * self.size : (x+1) * self.size] = normalize(i1)
		
		for i in range(0, w):
			show1(i, 0, residual[i] ** 0.4)
			show1(i, 1, psf[i] ** 0.4)
			show1(i, 2, moffat[i] ** 0.4)
			show1(i, 3, psf[i] - moffat[i]) 
		img = cv2.resize(img, (img.shape[1] * 2, img.shape[0] * 2), interpolation=cv2.INTER_NEAREST)
		cv2t.imshow(name, img)

	def fit(self, psf, residual = None):
		r2 = np.array([[ (x - self.mx) ** 2 + (y - self.my) ** 2 for x in range(0, self.size)] for y in range(0, self.size)])
		psf = np.array(psf)
		
		A = np.ones((psf.shape[1] * psf.shape[2], 2))
		
		def moffat2d(syx, alpha, beta):
			#s, y, x = syx
			#print(alpha, beta, mag, shift)
			moffat = (1 + (r2 / (alpha * alpha))) ** -beta
			ret = np.empty_like(psf)
			for i in range(0, len(psf)):
				#if residual is not None:
				moffat_i = cv2.filter2D(residual[i], -1, moffat)
				A[:, 0] = moffat_i.ravel()
				m, c = np.linalg.lstsq(A, psf[i].ravel())[0]
				ret[i] = c + m * moffat_i
			#print(ret)
			ret *= 1000.0
			return ret.ravel()#[(s, y, x)]

		slices = len(psf)

		x0 = np.arange(self.size)
		y0 = np.arange(self.size)
		s0 = np.arange(slices)
		s, y, x = np.meshgrid(s0, y0, x0, indexing='ij')
		syx = (s.ravel(), y.ravel(), x.ravel())
		s, y, x = syx
		z = psf[syx] * 1000.0

		min_alpha = (args.psf_filter_sigma - args.psf_filter_sigma_res)
		
		try:
			popt, pcov = curve_fit(moffat2d, syx, z, p0 = [3, 5], bounds = ([min_alpha, 1], [6.0, 10]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point')
			print ("fit1a", popt)
			self.show("fit1a", psf * 1000.0, residual, moffat2d(syx, *popt).reshape(psf.shape))
			
			for i in range(0,3):
				sigma = z - moffat2d(syx, *popt)
				ss = np.median(sigma ** 2) ** 0.5 * 0.1
				sigma[sigma < ss] = ss
				sigma *= 2
				popt, pcov = curve_fit(moffat2d, syx, z, p0 = popt, bounds = ([0.01, 1], [8.0, 10]), loss='soft_l1', verbose = 1, xtol=1e-12, ftol=1e-12, gtol=1e-12, jac = '3-point', sigma = sigma)
			
			print ("fit1b", popt)
			
			self.show("fit1b", psf * 1000.0, residual, moffat2d(syx, *popt).reshape(psf.shape))
		except  Exception as e:
			print(e)
			popt = [1.0, 4.765]
		self.set(popt[0], popt[1])




	def set(self, alpha, beta):
		self.alpha = alpha
		self.beta = beta
		
		r2 = np.array([[((x - self.mx) **2 + (y - self.my)**2) for x in range(self.size) ] for y in range(self.size) ], dtype=np.float)
		
		self.psf = (1 + r2 / (alpha **2 )) ** -beta

		cv2t.imshow("moffat", normalize(self.psf ** 0.4))
	
		self.psf /= self.psf.sum()
		
	def interpolate(self, s):
		if s < 0.01:
			s = 0.01
		return PsfMoffat(self.size, self.alpha * s, self.beta)
	
	def apply(self, img, flip = False):
		return cv2.filter2D(img, -1, self.psf)


class Psf:
	def set(self, psf):
		psf = np.array(psf)
		psf[np.where(psf < 0)] = 0
		psf /= psf.sum()
		self.psf = psf
		self.psf_flip = self.psf[::-1, ::-1]
		self.updated = False
		self.center = (0.0, 0.0)
		

	def extract(self, img, ptlist, psf_filter_sigma):
		psflist = get_psf_list(img, ptlist)
		self.from_psflist(psflist, psf_filter_sigma)

	def from_psflist(self, psflist, psf_filter_sigma):
		if len(psflist) == 0:
			return self.gaussian(None, 1.0)
		#psf = rrrl_simple(psflist, PsfMoffat(args.diameter * 2 + 1, 3, 2), 30)
		psf, target = rrrl_simple(psflist, PsfGauss(args.diameter * 2 + 1, psf_filter_sigma), 50)
		
#		psfgrad = (cv2.Sobel(psf, -1, 1,0,ksize=3)**2 + cv2.Sobel(psf, -1, 0,1,ksize=3)**2) ** 0.5
		#psfgrad2 = (cv2.Sobel(psfgrad, -1, 1,0,ksize=3)**2 + cv2.Sobel(psfgrad, -1, 0,1,ksize=3)**2) ** 0.5
		#cv2t.imshow("psfgrad2" , normalize(psfgrad2))
		
#		med_grad = float(np.mean(psfgrad))
		#print(med_grad)
		
		
		
#		psfgrad[np.where(psfgrad < med_grad * 3)] = 0
#		cv2t.imshow("psfgrad" , normalize(psfgrad))
		
#		floodmask = np.zeros((psf.shape[0] + 2, psf.shape[1] + 2), dtype=np.uint8)
#		cv2.floodFill(psfgrad, floodmask, (0,0), 255, loDiff = 0, upDiff = med_grad * 3, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY)
#		mask = 1 - floodmask[1:-1, 1:-1]
#		cv2t.imshow("psfgradmask", mask * 255)



		


		
		floodmask = np.zeros((psf.shape[0] + 2, psf.shape[1] + 2), dtype=np.uint8)
		bl_psf = cv2.medianBlur(psf, 3)
		bl_psf = cv2.GaussianBlur(bl_psf, (3, 3), 0)
		
		y, x = np.ogrid[-args.diameter:args.diameter + 1, -args.diameter:args.diameter + 1]
		r = np.array((x * x + y * y) ** 0.5 / args.diameter, dtype = np.float32) ** 2 / 4
		
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl_psf)
		
		bl_psf_r = bl_psf + r * (maxVal - minVal)
		thr = (maxVal - minVal) / 2.0 + minVal
		
		while True:
			cv2.floodFill(bl_psf_r, floodmask, maxLoc, 2, loDiff = 1000.0, upDiff = 0, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY)
			mask = floodmask[1:-1, 1:-1]
			bl_psf[np.where(mask > 0)] = 0
			minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(bl_psf)
			if maxVal < thr:
				break
		
		mask[0,:] = 0
		mask[-1,:] = 0
		mask[:, 0] = 0
		mask[:, -1] = 0
		
		cv2t.imshow("psf1" , normalize(psf ** 0.4))
		
#		mask = cv2.erode(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		#border = cv2.dilate(mask, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))) - mask


		low = np.median(psf)
		psf -= low
		psf[np.where(psf < 0)] = 0
		psf[np.where(mask == 0)] = 0

		thr = np.mean(psf[np.where(mask != 0)]) 
		mask = np.clip(psf, 0, thr) / thr
		cv2t.imshow("mask", mask)
		
		psf *= mask
		
		if psf.sum() == 0:
			psf[args.diameter, args.diameter] += 1
		cv2t.imshow("psf2" , normalize(psf ** 0.4))
			
		self.target = target
		#target = cv2.erode(target, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		self.residual = cv2.GaussianBlur(psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), args.psf_filter_sigma_res)
		#residual = cv2.dilate(residual, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
		
		cv2t.imshow("srcfit" , normalize(psf ** 0.4))
		
		#self.target = np.average(psflist, axis = 0, weights = weights)
		
		self.set(psf)
		#cv2t.imshow("psf%d" % id(self) , normalize(self.psf ** 0.5))
	
	def gaussian(self, img, sigma):
		psf = np.zeros((args.diameter * 2 + 1, args.diameter * 2 + 1), dtype=np.float64)
		psf[args.diameter, args.diameter] = 1
		psf = cv2.GaussianBlur(psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), sigma)
		self.set(psf)

	def update(self, cor_psf, dat, res):
		if not self.updated:
			self.updated = True
			self.psf = cv2.GaussianBlur(self.psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), 0.5)
			
		rs = res.sum()
		if rs == 0:
			return
			
		anchor = (int(res.shape[1] / 2), int(res.shape[0] / 2))
		res = res / rs
		
		cor_psf = cv2.divide(cv2.filter2D(cor_psf * dat, -1, res, anchor = anchor), cv2.filter2D(dat, -1, res, anchor = anchor))
		#cor_psf = cv2.filter2D(cor_psf, -1, res, anchor = anchor)


		cor_psf = np.array(cor_psf, dtype = np.float32)
		cor_psf = cv2.getRectSubPix(cor_psf, (args.diameter * 2 + 1, args.diameter * 2 + 1), (anchor[0] - self.center[0], anchor[1] - self.center[1]))
			
		#cor_psf /= np.mean(cor_psf)
		#print cor_psf
		#print "mean", np.mean(cor_psf)
		cor_psf = np.clip(cor_psf, 0.9, 1.1)
		cor_psf **= args.update_accel
		cor_psf = cv2.GaussianBlur(cor_psf,(3,3), 0)
		cv2t.imshow("cor_psf", normalize(cor_psf))
		if np.all(cor_psf >= 0) and not np.isnan(cor_psf).any():
			self.psf *= cor_psf

		cv2t.imshow("psf", normalize(self.psf ** 0.5))
		
		if self.psf.sum() == 0:
			self.psf[args.diameter, args.diameter] += 1

		self.psf = self.psf / self.psf.sum()
		self.psf_flip = self.psf[::-1, ::-1]

	def apply(self, img, flip = False):
		return cv2.filter2D(img, -1, (self.psf_flip, self.psf)[flip])
	
	def hfr(self):
		
		(x, y) = centroid(self.psf)
		x += args.diameter
		y += args.diameter
		
		psf = cv2.getRectSubPix(np.float32(self.psf), (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		return hfr(psf)
	
class VarPsf:
	def extract(self, img, ptlist, psf_filter_sigma):

		flatpsflist = []
		psflist = get_psf_list(img, ptlist)
		flatpsflist = np.array(psflist).reshape((len(psflist), -1))
	
		print("flatpsflist", flatpsflist.shape)

	
		cov = np.cov(flatpsflist)
		print("cov", cov)
		w, v = np.linalg.eig(cov)
		print("eig", w)
		print(v)
	
		print("eig shape:", v.shape)
		print("len psflist", len(psflist))
		print("cov shape", cov.shape)
	
		num_comp = min(20, w.shape[0])
	
		psfcomp = []
		self.psfcomplist = []
		for i, ev in enumerate(v):
			psf_s = np.zeros((args.diameter * 2 + 1, args.diameter * 2 + 1), np.float64)
			for j, c in enumerate(ev):
				psf_s += psflist[j] * float(c)
		
			psfcomp.append(psf_s.flatten())
			self.psfcomplist.append(psf_s)
		
			cv2.imwrite("psf%d.tif" % i, normalize(psf_s))
			if (i >= num_comp):
				break
	
		psfcomp = np.array(psfcomp).T
		
		psfcoef = []
		for psf in flatpsflist:
			psfcoef.append(np.linalg.lstsq(psfcomp, psf)[0])
		
		psfcoef = np.array(psfcoef).T
	
		Y = np.array([p[0] for p in ptlist])
		X = np.array([p[1] for p in ptlist])
	
		print("X", X)
		A = poly_array(X / 1000.0, Y / 1000.0, 3)
		print("coef fit")
	
		self.coef_fit = []
		for coefval in psfcoef:
			self.coef_fit.append(np.linalg.lstsq(A, coefval)[0])
	

		print("comp")
		self.comp_scale = []
		for c in self.coef_fit:
			v = poly_res(img.shape, c, 3)
			print(cv2.minMaxLoc(v))
			self.comp_scale.append(v)
		
		self.psfcomplist_flip = [psf[::-1, ::-1] for psf in self.psfcomplist]
		
		self.scale = None
		self.scale = self.apply(np.ones_like(img, dtype = np.float32))
		
		print("scale")
		print(cv2.minMaxLoc(self.scale))

	def apply(self, img, flip = False):
		res = np.zeros_like(img)
		for s, psf in zip(self.comp_scale, (self.psfcomplist_flip, self.psfcomplist)[flip]):
			res += cv2.filter2D(img * s, -1, psf)
		if self.scale is not None:
			res = res / self.scale
		return res


class TilePsf:
	def extract(self, img, ptlist, psf_filter_sigma, mask = None):
		self.shape = img.shape
		
		print("max img", np.amax(img))
		
		if mask is not None and np.array(mask).size <= 1:
			mask = None
		
		stars_tile = len(ptlist) / args.tiles ** 2
		print("stars per tile", stars_tile)
		stars_tile = max(stars_tile, 4)
		h, w = self.shape

		tile_size_h = int((h + args.tiles - 1) / args.tiles)
		tile_size_w = int((w + args.tiles - 1) / args.tiles)
		tile_overlap = int(tile_size_h * args.tile_overlap)
		self.tile_overlap = tile_overlap
		
		self.tiles = []
		self.sparse = False
		for y in range(0, h, tile_size_h):
			for x in range(0, w, tile_size_w):
				ul = (y, x)
				lr = (min(y + tile_size_h, h), min(x + tile_size_w, w))
				
				tile_overlap_e = tile_overlap
				eul_mo = (max(0, y - tile_overlap), max(0, x - tile_overlap))
				elr_mo = (min(y + tile_size_h + tile_overlap, h), min(x + tile_size_w + tile_overlap, w))
				if mask is not None and np.count_nonzero(mask[ul[0] : lr[0], ul[1]: lr[1]]) == 0:
					self.tiles.append((None, ul, lr, eul_mo, elr_mo))
					self.sparse = True
					continue
				while True:
					eul = (max(0, y - tile_overlap_e), max(0, x - tile_overlap_e))
					elr = (min(y + tile_size_h + tile_overlap_e, h), min(x + tile_size_w + tile_overlap_e, w))
				
					t_ptlist = []
					for  py, px in ptlist:
						if (py >= eul[0] + args.diameter and px >= eul[1] + args.diameter and py < elr[0] - args.diameter -1 and px < elr[1] - args.diameter -1
						        and  ( mask is None or
						          np.count_nonzero(mask[int(py) - args.diameter: int(py) + args.diameter + 1, int(px) - args.diameter: int(px) + args.diameter + 1]) == (args.diameter * 2 + 1)**2 )):
							t_ptlist.append((py - eul[0], px - eul[1]))
				
					psflist = get_psf_list(img[eul[0] : elr[0], eul[1]: elr[1]], t_ptlist, np.amax(img) * 0.95)
					if len(psflist) > stars_tile:
						break
					if eul == (0,0) and elr == (h,w):
						break
					tile_overlap_e *= 2
				if args.var_psf:
					psf = VarPsf()
					psf.extract(img[eul[0] : elr[0], eul[1]: elr[1]], t_ptlist, psf_filter_sigma)
					self.tiles.append((psf, ul, lr, eul, elr))
				else:
					psf = Psf()
					
					psf.from_psflist(psflist, psf_filter_sigma)
					self.tiles.append((psf, ul, lr, eul_mo, elr_mo))

		print(self.tiles)
		target_psf = [t[0].target for t in self.tiles if t[0] is not None]
		residual = [t[0].residual for t in self.tiles if t[0] is not None]

		self.moffat_base = PsfMoffat(args.diameter * 2 + 1, psf = target_psf, residual = residual)
		self.moffat = self.moffat_base

	def gaussian(self, img, sigma):
		
		self.shape = img.shape
		h, w = self.shape

		tile_size_h = int((h + args.tiles - 1) / args.tiles)
		tile_size_w = int((w + args.tiles - 1) / args.tiles)
		tile_overlap = int(tile_size_h * args.tile_overlap)
		self.tile_overlap = tile_overlap
		
		self.tiles = []
		self.sparse = False
		for y in range(0, h, tile_size_h):
			for x in range(0, w, tile_size_w):
				ul = (y, x)
				lr = (min(y + tile_size_h, h), min(x + tile_size_w, w))
				
				tile_overlap_e = tile_overlap
				eul = (max(0, y - tile_overlap_e), max(0, x - tile_overlap_e))
				elr = (min(y + tile_size_h + tile_overlap_e, h), min(x + tile_size_w + tile_overlap_e, w))
				
				psf = Psf()
				psf.gaussian(img[eul[0] : elr[0], eul[1]: elr[1]], sigma)
				self.tiles.append((psf, ul, lr, eul, elr))
		
	def apply(self, img, flip = False):
		if self.shape != img.shape:
			raise ValueError("psf shape differs")
	
	
		res = np.zeros_like(img)
		if self.sparse:
			mask = np.zeros_like(img)
		
		for psf, ul, lr, eul, elr in self.tiles:
			if psf is None:
				continue
			t_res = psf.apply(img[eul[0] : elr[0], eul[1]: elr[1]], flip)
			t_mask = np.zeros_like(t_res)
			t_mask[ul[0] - eul[0]:lr[0] - eul[0], ul[1] - eul[1]:lr[1] - eul[1]] = 1
			t_mask = cv2.blur(t_mask, (self.tile_overlap - 1, self.tile_overlap - 1))
			res[eul[0] : elr[0], eul[1]: elr[1]] += t_res * t_mask
			if self.sparse:
				mask[eul[0] : elr[0], eul[1]: elr[1]] += t_mask
			#cv2t.imshow("tile", mask)
			#cv2t.waitKey(0)

		if self.sparse:
			mask[mask == 0] = 100.0
			res /= mask
		self.moffat.apply(res)
		return res
		
	def update(self, cor_psf, dat, res):
		for psf, ul, lr, eul, elr in self.tiles:
			t_cor_psf = cor_psf[eul[0] : elr[0], eul[1]: elr[1]]
			t_dat = dat[eul[0] : elr[0], eul[1]: elr[1]]
			t_res = res[eul[0] : elr[0], eul[1]: elr[1]]
			t_mask = np.zeros_like(t_res)
			t_mask[ul[0] - eul[0]:lr[0] - eul[0], ul[1] - eul[1]:lr[1] - eul[1]] = 1
			t_mask = cv2.blur(t_mask, (self.tile_overlap - 1, self.tile_overlap - 1))
			t_dat *= t_mask
			psf.update(t_cor_psf, t_dat, t_res)
	
	def interpolate(self, s):
		self.moffat = self.moffat_base.interpolate(s)

	def hfr(self):
		hfrlist = []
		for psf, ul, lr, eul, elr in self.tiles:
			if psf is None:
				continue
			hfrlist.append(psf.hfr())
		return np.median(hfrlist)
	

def testPsf(shape, psf):
	test = np.zeros(shape, dtype = np.float64)
	test[:: args.diameter * 2, :: args.diameter * 2] = 1
	test = psf.apply(test)
	return test


def get_hfr(img, ptlist):
	hf = 0.0
	img = np.array(img, dtype = np.float32)
	for (y, x) in ptlist:
		psf = cv2.getRectSubPix(img, (args.diameter * 2 + 1, args.diameter * 2 + 1), (x, y))
		bg, w = psf_bg_w(psf)
		psf -= bg
		psf = np.abs(psf)
		
		hf += hfr(psf)
	return hf / len(ptlist)

def up_erode(img, r):
	size = (img.shape[1], img.shape[0])
	up = cv2.pyrUp(img)
	up = cv2.erode(up, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (r,r)))
	return cv2.pyrDown(up, dstsize = size)

def up_dilate(img, r):
	size = (img.shape[1], img.shape[0])
	up = cv2.pyrUp(img)
	up = cv2.dilate(up, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (r,r)))
	return cv2.pyrDown(up, dstsize = size)

def mean_clip2(src2):
	avg = cv2.mean(src2)[0]
	for i in range(0, 8):
		print("avg", avg)
		mask = cv2.compare(src2, float(avg) * 4, cv2.CMP_LE)
		mask[src2 == 0.0] = 0
		avg = cv2.mean(src2, mask=mask)[0]
	
	avg = float(avg)
	print("mean_{}: {}".format(src2.shape, avg ** 0.5))
	return avg


def mean_clip(src):

	avg2 = mean_clip2(src ** 2)
	return avg2 ** 0.5


class reg_pm_2:
	def step1(self, res_a, lm, m = None):
		g = []
		
		res = np.mean(res_a, axis = 0)
		p_res = np.pad(res, ((1, 1), (1, 1)), 'edge')
		
		#p_res -= cv2.GaussianBlur(p_res, (11,11), 0)
		
		grad_x = np.diff(p_res, axis = 1)
		grad_xm = np.mean([grad_x[0:-1, :], grad_x[1:, :]], axis = 0)
		grad_y = np.diff(p_res, axis = 0)
		grad_ym = np.mean([grad_y[:, 0:-1], grad_y[:, 1:]], axis = 0)
	
		lap = cv2.GaussianBlur(res, (7,7), 0) - res
		lap = np.pad(lap, ((1, 1), (1, 1)), 'edge')
		lap = np.mean([lap[:-1,:-1], lap[:-1,1:], lap[1:,:-1], lap[1:,1:]], axis = 0)
		lap[np.where(lap > 0)] = 0
			
			
		g = grad_xm ** 2 + grad_ym ** 2 + lap ** 2 * 2

		self.m = m
		if self.m is None:
			self.m = mean_clip2(g)

		l = lm ** 2 * self.m
		g = 1. / (1. + (g / l)) ** 2
		g = cv2.GaussianBlur(g, (3,3), 0)
		
		cv2t.imshow("g2_%d" % g.shape[1], normalize(g))
		self.gx = np.mean([g[1:, 1:-1], g[:-1, 1:-1]], axis = 0)
		self.gy = np.mean([g[1:-1, 1:], g[1:-1, :-1]], axis = 0)

	def step2(self, c):
		grad_x = np.diff(c, axis = 1)
		grad_y = np.diff(c, axis = 0)
		grad_xg = grad_x * self.gx
		grad_yg = grad_y * self.gy


		del grad_x
		del grad_y
	
		grad_xg2 = np.diff(grad_xg, axis = 1)
	
		grad_yg2 = np.diff(grad_yg, axis = 0)
		del grad_xg
		del grad_yg
	
		reg = np.zeros_like(c)
		reg[:, 1:-1] +=  grad_xg2
		reg[1:-1, :] +=  grad_yg2

		del grad_xg2
		del grad_yg2
		return reg


class Pyramid(object):
	def __init__(self, depth = 3, reg = None, l = None, mode = 'normal'):
		if reg is not None:
			depth = len(reg)
			self.l_mul = l
			self.reg = reg
		else:
			self.l_mul = [1.0] * depth
			self.reg = [1.0] * depth
		
		self.depth = depth
		self.mode = mode


	def gaussian_pyr(self, img, mode = 'normal'):
		kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
		img = np.array(img)
		gp = [img]
		for i in range(self.depth):
			try:
				if mode == 'openclose':
					img = (cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel) + cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)) / 2.0
				elif mode == 'open':
					img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)
				elif mode == 'close':
					img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)
				elif mode == 'median':
					img = cv2.medianBlur(img, 3)
				elif mode == 'erode':
					img = cv2.erode(img, kernel)
				elif mode == 'dilate':
					img = cv2.erode(img, kernel)
				elif mode != 'normal':
					raise Exception('bad mode', mode)
				
				img = cv2.pyrDown(img)
			except:
				pass
			gp.append(img)
		return gp

	def laplacian_pyr(self, img, mask = None):
		gp = self.gaussian_pyr(img, self.mode)
		if mask is not None:
			mask_gp = self.gaussian_pyr(mask)
			for i in range(self.depth + 1):
				gp[i][mask_gp[i] != 0] /= mask_gp[i][mask_gp[i] != 0]
		
		lp = [np.array(gp[self.depth])]
		for i in range(self.depth,0,-1):
			size = (gp[i - 1].shape[1], gp[i - 1].shape[0])
			up = cv2.pyrUp(gp[i], dstsize = size)
			lap = cv2.subtract(gp[i-1], up)
			if mask is not None:
				lap[mask_gp[i-1] == 0] = 0
			lp.append(lap)
		return lp[::-1]

	def collapse(self, pyr):
		depth = len(pyr)
		up = pyr[depth - 1]
		for i in range(depth - 2, -1, -1):
			size = (pyr[i].shape[1], pyr[i].shape[0])
			up = cv2.pyrUp(up, dstsize = size)
			up = up + pyr[i]
		return up
	
	def upscale_to(self, src, shape):
		shapes = []
		while shape[0] - src.shape[0] > 1 and shape[1] - src.shape[1] > 1:
			shapes.append(shape)
			shape = ((shape[0] + 1) // 2, (shape[1] + 1) // 2)
		for shape in shapes[::-1]:
			size = (shape[1], shape[0])
			src = cv2.pyrUp(src, dstsize = size)
		return src

	def downscale(self, src, n):
		for i in range(n):
			src = cv2.pyrDown(src)
		return src

class reg_pm_2_pyr(Pyramid):
	def __init__(self, depth = 3, reg = None, l = None):
		super(reg_pm_2_pyr, self).__init__(depth, reg, l)
		self.m = [1] * self.depth
	
	def step1(self, res_a, eval_noise):
		
		gp = []
		for res in res_a:
			gp.append(self.gaussian_pyr(res))
		
		self.levels = []
		for i, (img, lm) in enumerate(zip(zip(*gp), self.l_mul)):
			pm = reg_pm_2()
			
			if eval_noise:
				pm.step1(img, lm)
				self.m[i] = pm.m
			else:
				pm.step1(img, lm, self.m[i])
			self.levels.append(pm)
	
	def step2(self, c):
		gp = self.gaussian_pyr(c)
		resp = []
		for pm, img, r in zip(self.levels, gp, self.reg):
			print(pm.gx.shape, img.shape)
			resp.append(pm.step2(img) * r) 
		
		
		return self.collapse(resp)
		


class reg_pyr(Pyramid):
	def __init__(self, depth = 3, reg = None, l = None):
		super(reg_pyr, self).__init__(depth, reg, l)
		self.m = [1] * self.depth
	
	def step1(self, res_a, eval_noise):
		
		lps = []
		res = np.mean(res_a, axis = 0)
		lps.append(self.laplacian_pyr(res))
			
		self.g_lp = []
		for i in range(self.depth):
			g = []
			for j in range(len(lps)):
				lap = lps[j][i]
				
				g.append(lap * lap)
				
			
			g = np.mean(g, axis = 0)
			if eval_noise:
				self.m[i] = mean_clip2(g)
			lm = self.l_mul[i] ** 2 * self.m[i]

			g = 1. / (1. + (g / lm) ** 1)
			#if i == self.depth - 1:
			#	g = cv2.medianBlur(g, 3)
			#g = cv2.erode(g, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))
			#g = cv2.GaussianBlur(g, (3,3), 0)

			#g = cv2.dilate(g, cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3)))
		
			cv2t.imshow("g_pyr_%d" % len(self.g_lp), g)
			self.g_lp.append(g)
		

	def step2(self, c):
		lp = self.laplacian_pyr(c)
		reg_lp = []
		for i in range(self.depth):
			lp[i] *= self.g_lp[i]
			reg_lp.append(-(lp[i] - cv2.GaussianBlur(lp[i], (3,3), 0))  * self.reg[i])
			#-cv2.Laplacian(lp[i], -1, ksize = 3))
		
		
		return self.collapse(reg_lp)



class reg_pyr_flatten(Pyramid):
	def __init__(self, depth = 3, reg = None, l = None):
		super(reg_pyr_flatten, self).__init__(depth, reg, l, mode = args.reg_mode)
		self.m = [1] * self.depth
	
	def step1(self, res_a, eval_noise, weights = None):
		
		if weights is None:
			weights = [1.0] * len(res_a)
		lps = []
		#res = np.mean(res_a, axis = 0)
		for res_i in res_a:
			lps.append(self.laplacian_pyr(res_i))
			
		self.g_lp = []
		for i in range(self.depth):
			g = []
			g2 = []
			for j in range(len(lps)):
				lap = lps[j][i]
				
				g2.append(lap * lap * weights[j]**2)
				g.append(lap * weights[j])
				
			
			g2 = np.mean(g2, axis = 0)
			g = np.mean(g, axis = 0)
			
			if eval_noise:
				print(g2.shape)
				self.m[i] = mean_clip2(g2)
			
			#g = g2
			g = g * g
			
			lm = self.l_mul[i] ** 2 * self.m[i]

			g = (g / lm) ** 0.5
			g = g / (g + 1)
			cv2t.imshow("g_flat_%d" % len(self.g_lp), 1.0 - g)
			
			g = 1.0 - g ** self.reg[i]
			
			self.g_lp.append(g)
		

	def step2(self, c):
		lp = self.laplacian_pyr(c)
		reg_lp = []
		for i in range(self.depth):
			lp[i] *= self.g_lp[i]
			reg_lp.append(-lp[i])
		
		
		return self.collapse(reg_lp)


def pyr_noise_level(img):
	pyr = Pyramid(3)
	img = np.array(img, dtype=np.float)
	lp = pyr.laplacian_pyr(img)
	
	sigma2 = []
	for l in lp[:-1]:
		sigma2.append(mean_clip2(l * l))
	return np.sum(sigma2) ** 0.5


def signal_level(img):
	img = np.array(img, dtype=np.float)
	avg, sigma = cv2.meanStdDev(cv2.blur(img, (5, 5)) - cv2.blur(img, (100, 100)))
	sigma = float(sigma)
	print("signal_level", sigma)
	return sigma

def bg_level(src):
	res = cv2.blur(src, (3, 3))
	res = cv2.erode(res, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (args.diameter * 2 + 1,args.diameter * 2 + 1)))
	res = cv2.blur(res, (args.diameter * 2 + 1,args.diameter * 2 + 1))
	res = cv2.blur(res, (args.diameter * 2 + 1,args.diameter * 2 + 1))
	res = cv2.blur(res, (args.diameter * 2 + 1,args.diameter * 2 + 1))
	res = cv2.blur(res, (args.diameter * 2 + 1,args.diameter * 2 + 1))
	return res

def average_src(src, white, weights = None):
	sum_src = np.zeros_like(src[0], dtype = np.float32)
	sum_weights = np.zeros_like(src[0], dtype = np.float32)
	
	if weights is None:
		weights = [1.0] * len(src)
	
	gr = args.diameter * 2 + 1
	
	for i in range(0, len(src)):
		s = np.array(src[i], dtype = np.float32)
		w = np.array(weights[i], dtype = np.float32)
		w2 = cv2.blur(w, (gr, gr))
		w2 = cv2.blur(w2, (gr, gr))
		w2 *= w2
		w *= w2
		del w2

		sum_src += s / white[i] * w
		sum_weights += w

	res = cv2.divide(sum_src, sum_weights)
	res[np.where(sum_weights <= 0.001)] = args.zero / white[0]
	return res, sum_weights

def cluster_exps(exps):
	minv = np.amin(exps)
	maxv = np.amax(exps)
	hist, bins = np.histogram(exps, bins = np.arange(minv - 1.0, maxv + 2.0, 1.0), density=False)
	
	print(hist, bins)
	
	res = []
	while True:
		max_i = np.argmax(hist)
		if hist[max_i] == 0:
			break
		
		low = max(max_i - 1, 0)
		high = min(max_i + 1, len(hist) - 1)
		
		w = np.where((exps >= bins[low]) & (exps < bins[high + 1]))[0]
		res.append(w)
		
		hist[low] = 0
		hist[high] = 0
		hist[max_i] = 0
		print(hist)
	print(res)
	return res
		
def mask_overlaps(m1, m2):
	nz1 = np.count_nonzero(m1)
	nz2 = np.count_nonzero(m2)
	cross = np.count_nonzero(m1 * m2)
	ret = cross > min(nz1, nz2) * 0.8
	print('mask_overlap', nz1, nz2, cross, ret)
	return ret

def cluster_overlap(exp_clusters, masks):
	res = []
	for cl in exp_clusters:
		res_clusters = []
		res_masks = []
		for c in cl:
			added = False
			for i, m in enumerate(res_masks):
				if mask_overlaps(m, masks[c]):
					res_clusters[i].append(c)
					added = True
					break
			if not added:
				res_clusters.append([c])
				res_masks.append(masks[c])
		res += res_clusters
	return res


def save_output(it = None):
	res_ch = []
	for outc in range(0, outchannels):
		res_wb = res[outc] * white_balance[outc] + args.zero / 65535.0 * (1.0 - white_balance[outc])
		res_ch.append(cv2.multiply(res_wb, 65535.0, dtype = cv2.CV_16UC1))

	outidx = 0
	for i, fn in enumerate(outfiles):
		res_i = []
		for j in range(0, outfiles_c[i]):
			res_i.append(res_ch[outidx])
			outidx += 1
		kwargs = {}
                
		if np.asarray(transp[i]).shape == res[0].shape:
			if len(res_i) == 1:
				kwargs = {'planarconfig': 'contig', 'photometric' : 'minisblack'}
			#res_i.append(transp[i])
		
		res_i = cv2.merge(res_i)
		if it is not None:
			fn = "i%04d_%s" % (it, fn)
		tifffile.imsave(fn, res_i, **kwargs)
		del res_i
	del res_ch

def weighted_lin_fit(a, b, w):

	ma = np.average(a, weights = w)
	mb = np.average(b, weights = w)
	print("weighted_lin_fit average ", ma, mb)
	
	sa = np.average((a - ma)**2, weights = w) ** 0.5
	sb = np.average((b - mb)**2, weights = w) ** 0.5
	cor = np.average((a - ma) * (b - mb), weights = w) / (sa * sb)
	
	m = cor * sb / sa
	c = mb - m * ma
	return m, c

def histogram_weight(src, n = 50):
	isrc = np.array(src * n, dtype=np.int)
	isrc[isrc < 0] = 0
	isrc[isrc >= n] = n - 1
	hist, edges = np.histogram(isrc, bins=np.arange(n+1))
	print("hist", hist)
	m = max(np.median(hist), 1)
	print(1.0 / (np.array(hist, dtype=np.float) + m))
	histval = np.take(hist, isrc)
	ret = 1.0 / (np.array(histval, dtype=np.float) + m)
	return ret


def AvgDev(img):
	return np.mean(np.abs(img - np.median(img)))

def MAD(img):
	return np.median(np.abs(img - np.median(img)))

def BVMV(img):
	m = np.median(img)
	mdif = np.abs(img - m)
	Y = mdif / ( 9 * np.median(mdif))
	mask = (Y < 1.0)
	
	Ym2 = Y[mask]**2
	
	ret = img.size * np.sum(mdif[mask]**2 * (1.0 - Ym2)**4) / np.abs(np.sum((1.0 - Ym2)*(1.0 - 5 * Ym2)))**2
	return ret


def gradient_dif_filter(dif, w, r):
	difw = dif * w
	difw = cv2.blur(difw, (int(r / 2), int(r / 2)))
	mean_w = cv2.blur(w, (int(r / 2), int(r / 2)))

	if np.amin(dif.shape) > r * 5:
		dif = cv2.divide(difw, mean_w)
		shape = dif.shape
		resize_w = int((shape[1] + r - 1) / r)
		resize_h = int((shape[0] + r - 1) / r)
		dif = cv2.resize(dif, (resize_w, resize_h), interpolation=cv2.INTER_AREA)
		dif = cv2.medianBlur(dif, 5)
		dif = cv2.resize(dif, (shape[1], shape[0]), interpolation=cv2.INTER_LINEAR)
		dif = cv2.blur(dif, (r, r))
		dif = cv2.blur(dif, (r, r))
	else:
		difw = cv2.blur(difw, (r, r))
		mean_w = cv2.blur(mean_w, (r, r))
		difw = cv2.blur(difw, (r, r))
		mean_w = cv2.blur(mean_w, (r, r))
		difw = cv2.blur(difw, (r, r))
		mean_w = cv2.blur(mean_w, (r, r))
		dif = cv2.divide(difw, mean_w)

	return dif


def gradient_dif_filter2(dif, weight, r):
	h, w = dif.shape
	resize_w = int((w + r - 1) / r)
	resize_h = int((w + r - 1) / r)
	res = np.empty((resize_h, resize_w), dtype = dif.dtype)
	for i in range(0, resize_h):
		for j in range(0, resize_w):
			for s in range(1, w):
				y0 = np.clip(int((i - s) * h / resize_h), 0, h - 1)
				y1 = np.clip(int((i + 1 + s) * h / resize_h), 0, h - 1)
				x0 = np.clip(int((j - s) * w / resize_w), 0, w - 1)
				x1 = np.clip(int((j + 1 + s) * w / resize_w), 0, w - 1)
				tile = dif[y0:y1, x0:x1]
				tile_w = weight[y0:y1, x0:x1]
				tile_m = tile[tile_w > 0]
				if len(tile_m) > 0:
					break
			res[i, j] = np.median(tile_m)
	res = cv2.resize(res, (w, h), interpolation=cv2.INTER_LINEAR)
	res = cv2.blur(res, (r, r))
	res = cv2.blur(res, (r, r))
	res = cv2.blur(res, (r, r))


	return res

def mean_sigma_clip(a0, kappa=2, n=10):
	a = a0
	for i in range(0, n):
		m = np.mean(a)
		d2 = (a - m)**2
		s2 = np.mean(d2)
		d02 = (a0 - m)**2
		a = a0[d02 <= s2 * kappa**2]
	return m


#########################################################################################################


np.set_printoptions(precision=6, linewidth=160)
set_htr_size(args.diameter)

if args.test_ptlist:
	f = open(args.infile[0], 'rb')
	args, img, ptlist = pickle.load(f)
	f.close()
	set_htr_size(args.diameter)
	f_ptlist = filter_ptlist(img, ptlist, debug=True)
	sys.exit(0)

from cv2t import cv2t


src = []
src_white = []
src_sigma = []
src_median = []
src_signal_level = []

psfsrc = []
psfsrc_white = []
imgidx = []
transp = []
weights = []
maxval = []

exps = []
gradient_weight = []

outmap = []

outfiles = []
outfiles_c = []
outchannels = 0


nc = 1
for f in args.outfile.split(','):
	try:
		nc, fn = f.split(':')
		nc = int(nc)
	except:
		fn = f
	outfiles.append(fn)
	outfiles_c.append(nc)
	outchannels += nc

outc_num = [0] * outchannels


outc = 0
for f in args.infile:
	fn = f
	exp = 1.0
	grad_weight = 1.0
	if not os.path.isfile(fn):
		try:
			outc, fn = fn.split(':')
			outc = int(outc)
		except:
			pass

	for fn in fn.split(','):
		if not os.path.isfile(fn):
			try:
				fn, exp_s, grad_weight_s = fn.split('@')
				exp = float(exp_s)
				grad_weight = float(grad_weight_s)
			except: 
				try:
					fn, exp = fn.split('@')
					exp = float(exp)
				except:
					pass
		if not os.path.isfile(fn):
			print(fn, "not found")
			sys.exit(1)
			


		print("Read ", fn)
		img = tifffile.TiffFile(fn).asarray(memmap=True)
		if img is None:
			print('Failed to load fn:', fn)
			sys.exit(1)

		white = np.iinfo(img.dtype).max
		img = np.atleast_3d(img)
		if args.crop is not None:
			img = img[args.crop[0], args.crop[1]]
		h, w, channels = img.shape
		col = [1,1,1,3,3][channels]
	
		transp_c = white
		if channels > col:
			transp_c = img[:,:,col]
		
		#mask = np.amin(img, axis = 2)
		#img = extrapolate_transp(img[:,:,0:col], mask, add = True)
	
		outi = outc
		cidx = []
		for c in range(0, col):
			cidx.append(len(src))
			src.append(img[:,:, c])
			src_white.append(white)
			weights.append(transp_c)
			src_sigma.append(pyr_noise_level(img[:,:, c]))
			if channels > col:
				src_median.append(np.median(img[:,:, c][transp_c > 0]))
			else:
				src_median.append(np.median(img[:,:, c]))
			src_signal_level.append(signal_level(img[:,:, c]))
			
			mv = np.amax(cv2.medianBlur(img[:,:, c], 3))
			maxval.append(mv)
		
			outmap.append(outi)
			outc_num[outi] += 1
			outi += 1
		
			exps.append(exp)
			gradient_weight.append(grad_weight)
		imgidx.append(cidx)
		transp.append(transp_c)

srcmap = [[] for outc in range(outchannels)]
for c in range(0, len(src)):
	outc = outmap[c]
	srcmap[outc].append(c)

exps = np.array(exps, dtype = np.float64)

scales = 2.0 ** exps

scales /= np.amax(scales)
scales *= args.scale

white_balance = [1.0] * outchannels
for i, wb in enumerate(args.wb):
	white_balance[i] = wb
print("white balance", white_balance)

channel_scales = [1.0] * outchannels
for c in range(0, len(scales)):
	outc = outmap[c]
	channel_scales[outc] *= scales[c]
for outc in range(0, outchannels):
	channel_scales[outc] **= 1.0 / outc_num[outc]

print("channel_scales", channel_scales)

channel_weights = [0.0] * outchannels


for c in range(0, len(src)):
	print("scale sigma", scales[c], src_sigma[c], scales[c] * src_sigma[c], src_signal_level[c])
	outc = outmap[c]
	channel_weights[outc] += (src_signal_level[c] / src_sigma[c]) ** 2

channel_weights = np.array(channel_weights)** 0.5
print("channel_weights", channel_weights)

exp_clusters = cluster_exps(exps)
exp_clusters = cluster_overlap(exp_clusters, weights)
print('exp_clusters', exp_clusters)

sum_src, sumweights = average_src(src, src_white, weights)

print("sumweights", sumweights)
print("sum_src", sum_src)

if args.psffile:
	for f in [args.psffile]:
		img = tifffile.TiffFile(f).asarray(memmap=True)
		if img is None:
			print('Failed to load fn1:', f)
			sys.exit(1)

		white = np.iinfo(img.dtype).max
		img = np.atleast_3d(img)
		h, w, channels = img.shape
		col = [1,1,1,3,3][channels]

		for c in range(0, col):
			psfsrc.append(img[:,:, c])
			psfsrc_white.append(white)

	sum_psfsrc, sum_psfweights = average_src(psfsrc, psfsrc_white)
else:
	psfsrc = src
	psfsrc_white = src_white
	sum_psfsrc = sum_src



col = len(src)



#s_res = cv2.GaussianBlur(sum_src,(5,5),0)
#s_res = cv2.erode(s_res, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7)))
s_res = sum_src

if args.gaussian == 0.0:
	ptlist = find_ptlist(sum_psfsrc)

	show = normalize(sum_psfsrc ** 0.4)
	for (y, x) in ptlist:
		cv2.circle(show, (int(x),int(y)), 10, (255), 1)
	cv2.imwrite("pts_all.tif", show)

	del sum_psfsrc

	cluster_idx = [None] * col
	cluster_ptlists = []
	for cl_i, cl in enumerate(exp_clusters):
		cl_psfsrc = []
		cl_psfsrc_white = []
		cl_weights = []
		for i in cl:
			cl_psfsrc.append(psfsrc[i])
			cl_psfsrc_white.append(psfsrc_white[i])
			cl_weights.append(weights[i])
			cluster_idx[i] = cl_i

		sum_psfsrc, sum_psfweights = average_src(cl_psfsrc, cl_psfsrc_white, cl_weights)
		f = open("pts%d.data" % cl_i, 'wb')
		pickle.dump((args, sum_psfsrc, ptlist), f)
		f.close()
		cl_ptlist = filter_ptlist(sum_psfsrc, ptlist)

		show = normalize(sum_psfsrc ** 0.4)
		for (y, x) in cl_ptlist:
			cv2.circle(show, (int(x),int(y)), 10, (255), 1)
		cv2.imwrite("pts%d.tif" % cl_i, show)

		del sum_psfsrc
		cluster_ptlists.append(cl_ptlist)


psf = [None] * col
c_ptlists = [None] * col

skipped = [False] * col

res = [None] * outchannels
var = [1.0] * outchannels
reg_prev = [None] * outchannels
hist_weight = [None] * outchannels
kappa = 10.0

try:
	if args.load_psf:
		f = open(args.load_psf, 'rb')
		psf = pickle.load(f)
		f.close()
		for c in range(0, 3): #col):
			cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
	else:
		raise IOError
except:
	psf = [None] * col

	def step1(c, lock):
		print("start0  %d" % c)
		psf[c] = TilePsf()
		psfs = np.array(psfsrc[c], dtype = np.float32) / psfsrc_white[c]
		if args.gaussian == 0.0:
			c_ptlists[c] = cluster_ptlists[cluster_idx[i]]
			psf[c].extract(psfs, c_ptlists[c], args.psf_filter_sigma, mask = weights[c])
			cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
		else:
			psf[c].gaussian(psfs, args.gaussian)


	pfor.pfor(step1, list(range(0, col)))

	if args.save_psf:
		f = open(args.save_psf, 'wb')
		pickle.dump(psf, f)
		f.close()

def get_scaled_src_w(c, eval_noise = 1.0, med_bg = True):
	scaled_src = (np.array(src[c], dtype=np.float32) * scales[c] + args.zero * (1.0 - scales[c])) / src_white[c]

	weight = np.empty_like(src[c], dtype=np.float32)
	weight[:, :] = weights[c]

	if med_bg:
		scaled_src[weight == 0.0] = (src_median[c] * scales[c] + args.zero * (1.0 - scales[c])) / src_white[c]
	else:
		scaled_src[weight == 0.0] = 0.0

	gr = args.diameter
	w2 = cv2.blur(weight, (gr,gr)) / src_white[c]
	w2 = cv2.blur(w2, (gr,gr))
	w2 *= w2
	weight *= w2

	print("noise_level", c, scales[c] * src_sigma[c])
	weight /= src_white[c] * (scales[c] * src_sigma[c])**(2 * eval_noise)

	return scaled_src, weight


src_lp_cor = [None] * col

lp_depth_min = 2
lp_depth_max = int(np.log2(np.amin(src[0].shape)) - 1)
print("depth max", lp_depth_max)
pyr = Pyramid(depth = lp_depth_max - 1)
for outc in range(0, outchannels):
	srcpyr = [[None] * outc_num[outc] for i in range(lp_depth_min, lp_depth_max)]
#	hp_pyr = [None] * lp_depth_min
#	hp_pyr_stack = [[] for i in range(lp_depth_min)]
	weightpyr = [[None] * outc_num[outc] for i in range(lp_depth_min, lp_depth_max)]
	for si in range([1, 3][args.update_scales]):
		for ic in range(outc_num[outc]):
			c = srcmap[outc][ic]
			scaled_src, weight = get_scaled_src_w(c, med_bg = False)
			
			mask = np.ones_like(weight)
			mask[weight == 0.0] = 0.0
		
			slp = pyr.laplacian_pyr(scaled_src, mask = mask)
		
			weight *= gradient_weight[c]
			wgp = pyr.gaussian_pyr(weight)
			
			for i in range(lp_depth_min, lp_depth_max):
				if ic == 0:
					cv2.imwrite("p%d.tif" % (i), normalize(slp[i]))
					cv2.imwrite("w%d.tif" % (i), normalize(wgp[i]))

		
				srcpyr[i - lp_depth_min][ic] = slp[i]
			
				weight = cv2.erode(wgp[i], cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5)))
				weight = cv2.GaussianBlur(weight, (3,3), 0)
				weightpyr[i - lp_depth_min][ic] = weight
		
#			for i in range(lp_depth_min):
#				hp_pyr_stack[i].append(slp[i])
#				if len(hp_pyr_stack[i]) >= 5 or ic == outc_num[outc] - 1:
#					if hp_pyr[i] is None:
#						hp_pyr[i] = np.median(hp_pyr_stack[i], axis = 0) / ((outc_num[outc] + 4) // 5)
#					else:
#						hp_pyr[i] += np.median(hp_pyr_stack[i], axis = 0) / ((outc_num[outc] + 4) // 5)
#					hp_pyr_stack[i] = []

		
	
		res_pyr = []
		for i in range(lp_depth_max - lp_depth_min):
			weightpyr[i] = np.array(weightpyr[i])
			for it in range(0, 5):
				print("clip", i, np.count_nonzero(weightpyr[i]))
				avg = np.average(srcpyr[i], axis = 0, weights = weightpyr[i])
				d2 = (np.array(srcpyr[i]) - avg[np.newaxis, :, :]) ** 2
				s2 = np.average(d2, axis = 0, weights = weightpyr[i])
				weightpyr[i][d2 > s2 * 4] = 0
			
			res_pyr.append(avg)
			print(res_pyr[-1].shape)

		up_scales = []
		for ic in range(outc_num[outc]):
			ratios = []
			c = srcmap[outc][ic]
			for i in range(lp_depth_max - lp_depth_min - 1):
				where = (res_pyr[i] != 0) & (srcpyr[i][ic] != 0) & (res_pyr[i] * srcpyr[i][ic] > 0)
				r = res_pyr[i][where] / srcpyr[i][ic][where]
			
				ratios.append(np.exp(mean_sigma_clip(np.log(r), kappa=2)))
			r = np.median(ratios)
			print('ratios', ratios)
			up_scales.append(r)
		up_scales = np.array(up_scales) / np.exp(np.mean(np.log(up_scales)))
		if args.update_scales:
			for ic in range(outc_num[outc]):
				c = srcmap[outc][ic]
				scales[c] *= up_scales[ic]
		print("up_scales", up_scales)
			
	
	del srcpyr
	del weightpyr
	
	mean = pyr.collapse(res_pyr)
	#mean = pyr.upscale_to(mean, src[0].shape)
	
	for ic in range(outc_num[outc]):
		c = srcmap[outc][ic]
		scaled_src, weight = get_scaled_src_w(c)
		#dif = scaled_src - mean
		#dif = gradient_dif_filter(dif, weight, 2 ** lp_depth_min * 16)
		#dif = pyr.downscale(dif, lp_depth_min)
		scaled_src = pyr.downscale(scaled_src, lp_depth_min)
		weight = pyr.downscale(weight, lp_depth_min)
		dif = scaled_src - mean
		#dif = cv2.medianBlur(dif, 5)
		bl = int(args.gradient_radius / 2**lp_depth_min) + 1
		#dif = cv2.blur(dif, (bl, bl))
		#dif = cv2.blur(dif, (bl, bl))
		dif = gradient_dif_filter(dif, weight, bl)
			
		src_lp_cor[c] = cv2.GaussianBlur(dif, (5, 5), 0)
		cv2.imwrite("dif%d.tif" % (c), normalize(dif))

	
	#hp_pyr.append(mean)
	cv2.imwrite("pyr%d.tif" % (outc), normalize(mean**0.1))
	mean = pyr.upscale_to(mean, src[0].shape)
	res[outc] = mean

print("scales",scales)
res = np.array(res)
offset = np.empty_like(res)

noise = noise_level(sum_src) + 0.00000001
print("noise:", noise * 65535.0)

#reg1 = reg_pm_2_pyr(reg = args.reg2, l = args.reg_lambda2)
#reg2 = reg_pyr(reg = args.reg4, l = args.reg_lambda4)
reg3 = reg_pyr_flatten(reg = args.regf, l = args.reg_lambdaf)

#for c in range(0, col):
#	psf[c].interpolate(args.psf_filter_moffat_scale)

it = args.iter

for i in range(0, it):

	print(i)
	if i <= it / 2:
		for c in range(0, col):
			#psf[c].interpolate(args.psf_filter_moffat_scale * np.clip(i *  2.0 / it, 0, 1))
			psf[c].interpolate(args.psf_filter_moffat_scale)


	s_res = np.mean(res, axis = 0)
	print("check s_res", np.isnan(s_res).any(), cv2.minMaxLoc(s_res))

	#if i < 10:
	noise = noise_level(s_res) + 0.00000001
	print("noise:", noise * 65535.0)
	
	#starprot = -cv2.Laplacian(s_res, -1, ksize = 5)
	#starprot /= (noise * args.reg_starprot)
	#starprot[np.where(starprot < 1.0)] = 1.0
	
	#starprot = np.pad(starprot, ((1, 1), (1, 1)), 'edge')
	#starprot = np.mean([starprot[:-1,:-1], starprot[:-1,1:], starprot[1:,:-1], starprot[1:,1:]], axis = 0)
	#cv2t.imshow("starprot", normalize(1.0/starprot))

	setup = (i <= 3)

	sum_w = np.zeros_like(res)
	sum_corw = np.zeros_like(res)
	var_next = np.zeros_like(res)

	#reg_weight = 1 + (float(i) / it * args.robustness ** 0.5)**2
	dat_eps = 1.0 / args.robustness**4
	
	for outc in range(0, outchannels):
		hist_weight[outc] = histogram_weight(res[outc])
	
		#offset[outc] = np.amin(res[outc]) * args.dering
		if setup:
			offset[outc] = 0.0
		else:
			offset[outc] = bg_level(res[outc]) * args.dering
		res[outc] -= offset[outc]
		res[outc][res[outc] <=0] = 0.0000000001
	
	def step2(c, lock):
		if skipped[c]:
			return
		print("start2 %d %d" %(i,c))
		kappa = np.clip(3 - i, 0, 5) + 3
		outc = outmap[c]

		if setup:
			b_res = np.array(res[outc])
		else:
			b_res = psf[c].apply(res[outc])
			
		scaled_src, weight = get_scaled_src_w(c, eval_noise = np.clip(i / 5.0, 0.0, 1))
		
		where_over = np.where((src[c] > maxval[c] * args.overexp) & (scaled_src < b_res))
		weight[where_over] /= 1.0 + (src[c][where_over] - maxval[c] * args.overexp) / (src_white[c] / 1000.0)
		
		scaled_src_orig = scaled_src
		scaled_src = scaled_src_orig - offset[outc]
		
		#dif = scaled_src - b_res

		#gw = gradient_weight[c]
		
		#dat = weight
		
		#nii = 1
		#for ii in range(nii):
		#	difw = gradient_dif_filter2(dif, dat, args.gradient_radius)

		#	src_hp = scaled_src - difw
		#	cor_hp = cv2.divide(src_hp, b_res)
		#	cor_hp[np.where(cor_hp < 0.00001)] = 0.00001
			
		
		#	dat = b_res - (src_hp) * (1.0 - np.log(cor_hp))

		#	dat = dat * dat
			
		
		#	if ii == nii - 1:
		#		with lock:
		#			var_next[outc] += dat
		#			cv2t.imshow("var%d" % outc, dat / (var[outc] * kappa * kappa))
		#			if c == 1:
		#				cv2t.imshow("scaled_src%d" % c, normalize(np.clip(scaled_src_orig - 1010/65535.0,10/65535.0,1)** args.show_gamma))
		#		clip = np.where(dat > var[outc] * kappa * kappa)
				
		
		#	dat = (dat + dat_eps) ** -0.25
		
		#	dat *= weight
		
		scaled_src -= pyr.upscale_to(src_lp_cor[c], scaled_src.shape)
		
		cor = cv2.divide(scaled_src, b_res)
		cor[np.where(cor < 0.00001)] = 0.00001
		
		dat = b_res - scaled_src * (1.0 - np.log(cor))
		dat = dat * dat
		with lock:
			var_next[outc] += dat
			cv2t.imshow("var%d" % outc, dat / (var[outc] * kappa * kappa))
			if c == 1:
				cv2t.imshow("scaled_src%d" % c, normalize(np.clip(scaled_src_orig - 1010/65535.0,10/65535.0,1)** args.show_gamma))
		clip = np.where(dat > var[outc] * kappa * kappa)
		
		dat = (dat + dat_eps) ** -0.25
		dat *= weight
		
		dat[clip] = 0
		
		
		cor_psf = cor

		
		del b_res

		if setup:
			corw = cv2.multiply(dat, cor)
			w = np.array(dat)
		else:
			corw = psf[c].apply(cv2.multiply(dat, cor), flip = True)
			w =  psf[c].apply(dat, flip = True)
		#cor = psf.apply(cor, flip = True)
		corw[np.where(corw < 0.0)] = 0.0
		w[np.where(w < 0.0)] = 0.0

		with lock:
			#cv2.imwrite("reg_p%d_%d.tif" % (c, i), normalize(reg_p))
#			print("check res", np.isnan(res[c]).any(), cv2.minMaxLoc(res[c]))
		
#			print("check reg_p", np.isnan(reg_p).any(), cv2.minMaxLoc(reg_p))
#			print("check reg_m", np.isnan(reg_m).any(), cv2.minMaxLoc(reg_m))
			print("check dat", np.isnan(dat).any(), cv2.minMaxLoc(dat))
			print("check w", np.isnan(w).any(), cv2.minMaxLoc(w))
			print("check corw", np.isnan(corw).any(), cv2.minMaxLoc(corw))

			sum_w[outc] += w
			sum_corw[outc] += corw
		
		if c < 3:
			cv2t.imshow("dat%d" % c, normalize(-dat**0.5))
		
				
		if args.update_iter > 0 and i > args.update_iter:
			psf[c].update(cor_psf, dat, res[outc])
		
		print("end2 %d %d" %(i,c))
	pfor.pfor(step2, list(range(0, col)) if i % 2 == 0 else reversed(list(range(0, col))))
	

	var = var_next

	norm_w = []
	for sw in sum_w:
		norm_w.append(sw / np.median(sw))
	norm_w = 1.0 / np.mean(norm_w, axis = 0)
	
	norm_w = cv2.dilate(norm_w, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (args.weight_dilate * 2 + 1, args.weight_dilate * 2 + 1)))
	norm_w = np.clip(norm_w, 1.0, 10.0)
	norm_w = cv2.GaussianBlur(norm_w, (args.weight_dilate * 2 + 1, args.weight_dilate * 2 + 1), 0)
		
	cv2t.imshow("norm_w", norm_w / 10.0)

	#reg1.step1(res, i < args.lambda_eval_iter)
	#reg2.step1(res, i < args.lambda_eval_iter)
	reg3.step1(res + offset, i < args.lambda_eval_iter, weights = channel_weights)

	for outc in range(0, outchannels):
		var[outc] /= outc_num[outc]
		print("check res_pre", np.isnan(res[outc]).any(), cv2.minMaxLoc(res[outc]))

		#cor = cv2.divide(sum_corw[outc], sum_w[outc])

		#res[outc] *= cor
	
	
		#reg_weight = args.reg * min(float(i) / (it * 0.3), 1)
		reg = reg3.step2(res[outc])
		print("check reg1", np.isnan(reg).any(), cv2.minMaxLoc(reg))
		#print("check reg2", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		missing = np.where(sum_w[outc] < 1.0)
		sum_w[outc][missing] = 1

		#reg = cv2.divide(reg, sum_w[outc])
		#reg *= np.mean(sum_w[outc])
		print("check reg3", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		#mean, stddev = cv2.meanStdDev(reg)
		#stddev = float(stddev)
		#reg = np.clip(reg, -stddev * 3, stddev * 3)

		
		#hp = cv2.Laplacian(res[outc], -1, ksize = 7)
		#coefs = np.linalg.lstsq(np.array([reg.ravel()]).T, hp.ravel().T)[0]
		#print("reg fit ", coefs)
		
		
		#reg = cv2.divide(reg, np.clip(res[outc], 1024.0/65535.0, 1))

		#print("check reg4", np.isnan(reg).any(), cv2.minMaxLoc(reg))

		reg[missing] = 0
		print("check reg5", np.isnan(reg).any(), cv2.minMaxLoc(reg))


		#reg[np.where(src[c] > 0.95)] /= 1000
	
		#reg = cv2.GaussianBlur(reg, (3,3), 0.6)
		#if i > 0:
		#	reg = reg * 0.1 + reg_prev[outc] * 0.9
		#	reg_prev[outc] = reg
		#else:
		#	reg_prev[outc] = (reg * 0.1)
		
		#print reg
		reg *= (1.0 + args.reg_plus * (np.clip(norm_w, 1 , 3) - 1.0) / 2.0)
		reg_p = np.array(reg)
		reg_p[np.where(reg < 0.)] = 0.
		reg_m = reg - reg_p
		reg = reg_m + reg_p
	
		#res[outc] *= cv2.divide(1 + reg_p, 1 - reg_m)

		#cor = cv2.divide(sum_corw[outc] + reg_p, sum_w[outc] - reg_m)
		cor = cv2.divide(sum_corw[outc], sum_w[outc])
		cor[missing] = 1.0
		cor[np.where(cor < 0.01)] = 0.01
		cor[np.where(cor > 100.)] = 100.
		
		res[outc] *= cor
		if setup:
			res[outc] = cv2.GaussianBlur(res[outc], (5, 5), 0)
		else:
			res[outc] += reg
		
		minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(res[outc])
		maxVal = min(maxVal, 1.0)
		avg, stddev = cv2.meanStdDev(res[outc])
		
		floodmask = np.zeros((res[outc].shape[0] + 2, res[outc].shape[1] + 2), dtype=np.uint8)
		cv2.floodFill(res[outc], floodmask, minLoc, 2, loDiff = 0, upDiff = (maxVal - minVal) * args.top_thres, flags = 256 + 8 + cv2.FLOODFILL_MASK_ONLY + cv2.FLOODFILL_FIXED_RANGE)
		floodmask = floodmask[1:-1, 1:-1]
		#cv2t.imshow("fm%d" % outc, normalize(floodmask))
		top = cv2.dilate(res[outc], cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)))
		top = cv2.erode(top, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15)))
		top[floodmask > 0] = 0
		cv2t.imshow("top%d" % outc, normalize(top))
		res[outc] = np.maximum(res[outc], top)

		if args.erode > 0 and  i < args.erode_iter:
			erod = up_erode(res[outc], 3)
			res[outc] = erod * args.erode + res[outc] * (1.0 - args.erode)


		if i < args.blur_iter:
			res[outc] = cv2.GaussianBlur(res[outc], (17, 17), args.blur_sigma * (1.0 - i / args.blur_iter))

		print("check res", np.isnan(res[outc]).any(), cv2.minMaxLoc(res[outc]))

		print("check reg_p", np.isnan(reg_p).any(), cv2.minMaxLoc(reg_p))
		print("check reg_m", np.isnan(reg_m).any(), cv2.minMaxLoc(reg_m))
		

		cv2t.imshow("reg_p%d" % outc, normalize(reg_p))
		cv2t.imshow("reg_m%d" % outc, normalize(-reg_m))
		
		res[outc] += offset[outc]
		cv2t.imshow("res%d" % outc, normalize(np.clip(res[outc] - 1010/65535.0,10/65535.0,1)** args.show_gamma))
		cv2t.imshow("off%d" % outc, normalize(offset[outc]))

#		if args.gaussian == 0.0:
#			curhfr = get_hfr(res[outc], ptlist)
#			print("hfr", curhfr)
			#if i < 3 and curhfr > 2:
			#	res = cv2.erode(res, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)))

	if args.update_iter > 0:
		hfr_list = []
		for c in range(0, col):
			hfr_list.append(psf[c].hfr())

		print("res_hfr", i, hfr_list)
		
#		if i == 150:
#			s_hfrlist = sorted(hfr_list)
#			thr = s_hfrlist[col / 8]
#			for c in range(0, col):
#				skipped[c] = hfr_list[c] > thr
#				cv2.imwrite("testpsf%d.tif" % (c), normalize(testPsf(psfsrc[c].shape, psf[c])))
#			print "hfr thr", thr
#			print skipped
			
	save_output(i)
	

	cv2t.waitKey(1)
	gc.collect()
	
#for outc in range(0, outchannels):
#	if args.gaussian == 0.0:
#		psf = TilePsf()
#		pts = set_psf_level(res[outc], ptlist)
#		psf.extract(res[outc], pts, 0.01)
#		cv2.imwrite("testpsf%d_res.tif" % (outc), normalize(testPsf(src[outc].shape, psf)))
	

save_output()

cv2t.waitKey(1000)
